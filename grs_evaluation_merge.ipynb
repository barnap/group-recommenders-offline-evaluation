{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import settings.config as cfg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "preprocessed_dataset_folder = cfg.preprocessed_dataset_folder\n",
    "individual_rs_strategy = cfg.individual_rs_strategy\n",
    "aggregation_strategies = cfg.aggregation_strategies\n",
    "recommendations_number = cfg.recommendations_number\n",
    "individual_rs_validation_folds_k = cfg.individual_rs_validation_folds_k\n",
    "group_rs_evaluation_folds_k = cfg.group_rs_evaluation_folds_k\n",
    "evaluation_strategy = cfg.evaluation_strategy\n",
    "metrics = cfg.metrics\n",
    "\n",
    "print(cfg.feedback_polarity_debiasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4805, 5428]},\n",
       " 1: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5251, 146]},\n",
       " 2: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3916, 4539]},\n",
       " 3: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2059, 5558]},\n",
       " 4: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1789, 463]},\n",
       " 5: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3234, 4068]},\n",
       " 6: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5216, 4855]},\n",
       " 7: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [339, 5736]},\n",
       " 8: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [153, 4515]},\n",
       " 9: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3450, 2157]},\n",
       " 10: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [707, 2380]},\n",
       " 11: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [379, 3986]},\n",
       " 12: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3752, 3705]},\n",
       " 13: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [209, 1288]},\n",
       " 14: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3929, 751]},\n",
       " 15: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4751, 497]},\n",
       " 16: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3308, 197]},\n",
       " 17: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [417, 1226]},\n",
       " 18: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4699, 5990]},\n",
       " 19: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2498, 3463]},\n",
       " 20: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3193, 4620, 3834, 4336]},\n",
       " 21: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2327, 2358, 671, 1532]},\n",
       " 22: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5896, 5350, 4113, 3112]},\n",
       " 23: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [602, 404, 1534, 3293]},\n",
       " 24: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3740, 3842, 5716, 3111]},\n",
       " 25: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1867, 4910, 2163, 4817]},\n",
       " 26: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1723, 2447, 1826, 1002]},\n",
       " 27: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2720, 5726, 3355, 5375]},\n",
       " 28: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4455, 1427, 4391, 5096]},\n",
       " 29: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2218, 4055, 4617, 2873]},\n",
       " 30: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1551, 2534, 5334, 4506]},\n",
       " 31: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [867, 3743, 729, 3771]},\n",
       " 32: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1969, 3791, 75, 1891]},\n",
       " 33: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [6036, 4306, 4495, 5157]},\n",
       " 34: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5470, 2348, 2466, 2433]},\n",
       " 35: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4787, 2909, 5884, 1140]},\n",
       " 36: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2307, 4005, 3306, 3542]},\n",
       " 37: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1514, 2163, 99, 1136]},\n",
       " 38: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5741, 5573, 589, 5770]},\n",
       " 39: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5167, 790, 1518, 431]},\n",
       " 40: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3148, 784, 2597, 6014, 3195, 2424, 187, 4874]},\n",
       " 41: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2510, 5161, 1136, 4001, 5018, 165, 173, 4958]},\n",
       " 42: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2830, 3352, 3537, 2138, 3470, 401, 4360, 4101]},\n",
       " 43: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5320, 5423, 918, 4, 2708, 3836, 4318, 1632]},\n",
       " 44: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [491, 1357, 4708, 1947, 140, 2146, 5530, 446]},\n",
       " 45: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4482, 210, 5756, 1520, 3973, 5051, 2582, 497]},\n",
       " 46: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1866, 4876, 65, 4003, 2698, 3855, 2731, 629]},\n",
       " 47: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4727, 4445, 3875, 1577, 2681, 3843, 4407, 3700]},\n",
       " 48: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1657, 2128, 5424, 1089, 4613, 5892, 832, 3633]},\n",
       " 49: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3588, 3602, 5963, 409, 1820, 1932, 5462, 5819]},\n",
       " 50: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4269, 4569, 1562, 4714, 2971, 6003, 3487, 470]},\n",
       " 51: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2252, 3369, 5630, 5817, 1536, 1082, 5692, 2344]},\n",
       " 52: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2491, 4959, 3670, 158, 6006, 749, 1473, 2567]},\n",
       " 53: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1917, 1000, 4182, 3256, 1531, 357, 5578, 4853]},\n",
       " 54: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4131, 2227, 5176, 691, 1240, 422, 238, 3158]},\n",
       " 55: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3219, 3129, 3643, 3326, 964, 3246, 2025, 3114]},\n",
       " 56: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5652, 640, 2384, 480, 3659, 1103, 5932, 2577]},\n",
       " 57: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4182, 4312, 677, 5719, 546, 819, 2089, 1357]},\n",
       " 58: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1126, 3482, 2410, 5749, 698, 513, 837, 2050]},\n",
       " 59: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1989, 1619, 1617, 319, 4190, 4578, 2623, 1879]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ratings_df = pd.read_csv(preprocessed_dataset_folder+\"/ratings.csv\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "group_composition = pickle.load(open(preprocessed_dataset_folder+\"/group_composition.pkl\", \"rb\"))\n",
    "display(group_composition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "\n",
    "# Train individual recommender system and predict ratings\n",
    "def train_individual_rs_and_get_predictions(training_df, test_df):\n",
    "    if cfg.individual_rs_strategy == \"LENSKIT_CF_USER\":\n",
    "        print(cfg.individual_rs_strategy)\n",
    "        return train_lenskit_cf_user_rs_and_get_predictions(training_df, test_df)\n",
    "    if cfg.individual_rs_strategy == \"LENSKIT_CF_ITEM\":\n",
    "        print(cfg.individual_rs_strategy)\n",
    "        return train_lenskit_cf_item_rs_and_get_predictions(training_df, test_df)    \n",
    "    return None\n",
    "    \n",
    "from lenskit.algorithms import Recommender\n",
    "from lenskit.algorithms.user_knn import UserUser\n",
    "from lenskit.algorithms.item_knn import ItemItem\n",
    "\n",
    "# Train lenskit CF user-user individual recommender system and predict ratings\n",
    "def train_lenskit_cf_user_rs_and_get_predictions(training_df, test_df):\n",
    "    if cfg.individual_rs_validation_folds_k <=0:\n",
    "        print(\"training\")\n",
    "        # Basic implementation: no hyperparameters validation\n",
    "        user_user = UserUser(15, min_nbrs=3)  # Minimum (3) and maximum (15) number of neighbors to consider\n",
    "        recsys = Recommender.adapt(user_user)\n",
    "        recsys.fit(training_df)\n",
    "        \n",
    "        print(\"evaluating predictions\")\n",
    "        # Evaluating predictions \n",
    "        test_df['predicted_rating'] = recsys.predict(test_df)\n",
    "        print(\"Done!\")\n",
    "        return test_df\n",
    "    return None    \n",
    "\n",
    "# Train lenskit CF item-item individual recommender system and predict ratings\n",
    "def train_lenskit_cf_item_rs_and_get_predictions(training_df, test_df):\n",
    "    if cfg.individual_rs_validation_folds_k <=0:\n",
    "        print(\"training\")\n",
    "        # Basic implementation: no hyperparameters validation\n",
    "        item_item = ItemItem(15, min_nbrs=3)  # Minimum (3) and maximum (15) number of neighbors to consider\n",
    "        recsys = Recommender.adapt(item_item)\n",
    "        recsys.fit(training_df)\n",
    "        \n",
    "        print(\"evaluating predictions\")\n",
    "        # Evaluating predictions \n",
    "        test_df['predicted_rating'] = recsys.predict(test_df)\n",
    "        print(\"Done!\")\n",
    "        return test_df\n",
    "    return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Aggregation strategies\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class AggregationStrategy(ABC):\n",
    "    \n",
    "    @staticmethod\n",
    "    def getAggregator(strategy):            \n",
    "        if strategy==\"ADD\":\n",
    "            return AdditiveAggregator()\n",
    "        elif strategy==\"LMS\":\n",
    "            return LeastMiseryAggregator()\n",
    "        elif strategy==\"BASE\":\n",
    "            return BaselinesAggregator()\n",
    "        elif strategy==\"GFAR\":\n",
    "            return GFARAggregator()     \n",
    "        elif strategy==\"EPFuzzDA\":\n",
    "            return EPFuzzDAAggregator()        \n",
    "        return None\n",
    "    \n",
    "    @abstractmethod\n",
    "    def generate_group_recommendations_for_group(self, group_ratings, recommendations_number):\n",
    "        pass\n",
    "    \n",
    "\n",
    "class AdditiveAggregator(AggregationStrategy):    \n",
    "    def generate_group_recommendations_for_group(self, group_ratings, recommendations_number):\n",
    "        aggregated_df = group_ratings.groupby('item').sum()\n",
    "        aggregated_df = aggregated_df.sort_values(by=\"predicted_rating\", ascending=False).reset_index()[['item', 'predicted_rating']]\n",
    "        recommendation_list = list(aggregated_df.head(recommendations_number)['item'])\n",
    "        return {\"ADD\" : recommendation_list}\n",
    "    \n",
    "class LeastMiseryAggregator(AggregationStrategy):    \n",
    "    def generate_group_recommendations_for_group(self, group_ratings, recommendations_number):\n",
    "        # aggregate using least misery strategy\n",
    "        aggregated_df = group_ratings.groupby('item').min()\n",
    "        aggregated_df = aggregated_df.sort_values(by=\"predicted_rating\", ascending=False).reset_index()[['item', 'predicted_rating']]\n",
    "        recommendation_list = list(aggregated_df.head(recommendations_number)['item'])\n",
    "        return {\"LMS\" : recommendation_list}\n",
    "\n",
    "class BaselinesAggregator(AggregationStrategy):    \n",
    "    def generate_group_recommendations_for_group(self, group_ratings, recommendations_number):\n",
    "        # aggregate using least misery strategy\n",
    "        aggregated_df = group_ratings.groupby('item').agg({\"predicted_rating\": [np.sum, np.prod,np.min,np.max]})\n",
    "        aggregated_df = aggregated_df[\"predicted_rating\"].reset_index()\n",
    "        # additive\n",
    "        \n",
    "        add_df = aggregated_df.sort_values(by=\"sum\", ascending=False).reset_index()[['item', 'sum']]\n",
    "        add_recommendation_list = list(add_df.head(recommendations_number)['item'])\n",
    "        # multiplicative\n",
    "        mul_df = aggregated_df.sort_values(by=\"prod\", ascending=False).reset_index()[['item', 'prod']]\n",
    "        mul_recommendation_list = list(mul_df.head(recommendations_number)['item'])\n",
    "        # least misery\n",
    "        lms_df = aggregated_df.sort_values(by=\"amin\", ascending=False).reset_index()[['item', 'amin']]\n",
    "        lms_recommendation_list = list(lms_df.head(recommendations_number)['item'])\n",
    "        # most pleasure\n",
    "        mpl_df = aggregated_df.sort_values(by=\"amax\", ascending=False).reset_index()[['item', 'amax']]\n",
    "        mpl_recommendation_list = list(mpl_df.head(recommendations_number)['item'])\n",
    "        return {\n",
    "            \"ADD\" : add_recommendation_list, \n",
    "            \"MUL\" : mul_recommendation_list, \n",
    "            \"LMS\" : lms_recommendation_list, \n",
    "            \"MPL\" : mpl_recommendation_list\n",
    "        }\n",
    "    \n",
    "class GFARAggregator(AggregationStrategy):\n",
    "    #implements GFAR aggregation algorithm. For more details visit https://dl.acm.org/doi/10.1145/3383313.3412232\n",
    "\n",
    "    #create an index-wise top-k selection w.r.t. list of scores\n",
    "    def select_top_n_idx(self, score_df, top_n, top='max', sort=True):\n",
    "        if top != 'max' and top != 'min':\n",
    "            raise ValueError('top must be either Max or Min')\n",
    "        if top == 'max':\n",
    "            score_df.loc[score_df.index,\"predicted_rating_rev\"] = -score_df[\"predicted_rating\"]\n",
    "\n",
    "        select_top_n = top_n\n",
    "        top_n_ind = np.argpartition(score_df.predicted_rating_rev, select_top_n)[:select_top_n]        \n",
    "        top_n_df = score_df.iloc[top_n_ind]\n",
    "\n",
    "        if sort:\n",
    "            return top_n_df.sort_values(\"predicted_rating_rev\")\n",
    "\n",
    "        return top_n_df\n",
    "\n",
    "    # borda count that is limited only to top-max_rel_items, if you are not in the top-max_rel_items, you get 0\n",
    "    def get_borda_rel(self, candidate_group_items_df, max_rel_items):  \n",
    "        from scipy.stats import rankdata\n",
    "        top_records = self.select_top_n_idx(candidate_group_items_df, max_rel_items, top='max', sort=False)        \n",
    "        \n",
    "        rel_borda = rankdata(top_records[\"predicted_rating_rev\"].values, method='max')\n",
    "        #candidate_group_items_df.loc[top_records.index,\"borda_score\"] = rel_borda\n",
    "        return (top_records.index, rel_borda)\n",
    "\n",
    "    # runs GFAR algorithm for one group\n",
    "    def gfar_algorithm(self, group_ratings, top_n: int, relevant_max_items: int, n_candidates: int):      \n",
    "        \n",
    "        group_members = group_ratings.user.unique()\n",
    "        group_size = len(group_members)\n",
    "        \n",
    "        localDF = group_ratings.copy()\n",
    "        localDF[\"predicted_rating_rev\"] = 0.0\n",
    "        localDF[\"borda_score\"] = 0.0\n",
    "        localDF[\"p_relevant\"] = 0.0\n",
    "        localDF[\"prob_selected_not_relevant\"] = 1.0\n",
    "        localDF[\"marginal_gain\"] = 0.0\n",
    "        \n",
    "        #filter-out completely irrelevant items to decrease computational complexity        \n",
    "        #top_candidates_ids_per_member = []\n",
    "        #for uid in  group_members:\n",
    "        #    per_user_ratings = group_ratings.loc[group_ratings.user == uid]\n",
    "        #    top_candidates_ids_per_member.append(select_top_n_idx(per_user_ratings, n_candidates, sort=False)[\"item\"].values)\n",
    "        \n",
    "\n",
    "        #top_candidates_idx = np.unique(np.array(top_candidates_ids_per_member))\n",
    "        \n",
    "        # get the candidate group items for each member\n",
    "        #candidate_group_ratings = group_ratings.loc[group_ratings[\"items\"].isin(top_candidates_idx)]\n",
    "        \n",
    "        \n",
    "        for uid in group_members:\n",
    "            per_user_candidates = localDF.loc[localDF.user == uid]\n",
    "            borda_index, borda_score = self.get_borda_rel(per_user_candidates, relevant_max_items)\n",
    "            localDF.loc[borda_index,\"borda_score\"] = borda_score\n",
    "        \n",
    "            total_relevance_for_users = localDF.loc[borda_index,\"borda_score\"].sum()\n",
    "            localDF.loc[borda_index,\"p_relevant\"] = localDF.loc[borda_index,\"borda_score\"] / total_relevance_for_users\n",
    "            \n",
    "\n",
    "        selected_items = []\n",
    "\n",
    "        # top-n times select one item to the final list\n",
    "        for i in range(top_n):\n",
    "            localDF.loc[:,\"marginal_gain\"] = localDF.p_relevant * localDF.prob_selected_not_relevant\n",
    "            item_marginal_gain = localDF.groupby(\"item\")[\"marginal_gain\"].sum()\n",
    "            # select the item with the highest marginal gain\n",
    "            item_pos = item_marginal_gain.argmax()\n",
    "            item_id = item_marginal_gain.index[item_pos]\n",
    "            selected_items.append(item_id)\n",
    "\n",
    "            # update the probability of selected items not being relevant\n",
    "            for uid in group_members:\n",
    "                winner_row = localDF.loc[((localDF[\"item\"]== item_id)&(localDF[\"user\"]== uid))]\n",
    "                \n",
    "                #only update if any record for user-item was found\n",
    "                if winner_row.shape[0]>0:\n",
    "                    p_rel = winner_row[\"p_relevant\"].values[0]\n",
    "                    p_not_selected = winner_row[\"prob_selected_not_relevant\"].values[0] * (1 - p_rel)\n",
    "                \n",
    "                    localDF.loc[localDF[\"user\"]== uid,\"prob_selected_not_relevant\"] = p_not_selected\n",
    "            \n",
    "            #remove winning item from the list of candidates\n",
    "            localDF.drop(localDF.loc[localDF[\"item\"] == item_id].index, inplace=True)\n",
    "        return selected_items\n",
    "    \n",
    "    def generate_group_recommendations_for_group(self, group_ratings, recommendations_number):\n",
    "        selected_items = self.gfar_algorithm( group_ratings, recommendations_number, 20, 500)        \n",
    "        return {\"GFAR\" : selected_items}\n",
    "    \n",
    "    \n",
    "class EPFuzzDAAggregator(AggregationStrategy):\n",
    "    #implements EP-FuzzDA aggregation algorithm. For more details visit https://dl.acm.org/doi/10.1145/3450614.3461679\n",
    "\n",
    "    def ep_fuzzdhondt_algorithm(self, group_ratings, top_n, member_weights=None):\n",
    "        group_members = group_ratings.user.unique()\n",
    "        all_items = group_ratings[\"item\"].unique()\n",
    "        group_size = len(group_members)\n",
    "\n",
    "        if not member_weights:\n",
    "            member_weights = [1./group_size] * group_size\n",
    "        member_weights = pd.DataFrame(pd.Series(member_weights, index=group_members))\n",
    "        \n",
    "        localDF = group_ratings.copy()\n",
    "      \n",
    "        candidate_utility = pd.pivot_table(localDF, values=\"predicted_rating\", index=\"item\", columns=\"user\", fill_value=0.0)\n",
    "        candidate_sum_utility = pd.DataFrame(candidate_utility.sum(axis=\"columns\"))\n",
    "        \n",
    "        total_user_utility_awarded = pd.Series(np.zeros(group_size), index=group_members)\n",
    "        total_utility_awarded = 0.\n",
    "\n",
    "        selected_items = []\n",
    "        # top-n times select one item to the final list\n",
    "        for i in range(top_n):\n",
    "            # print()\n",
    "            # print('Selecting item {}'.format(i))\n",
    "            # print('Total utility awarded: ', total_utility_awarded)\n",
    "            # print('Total user utility awarded: ', total_user_utility_awarded)\n",
    "\n",
    "            prospected_total_utility = candidate_sum_utility + total_utility_awarded #pd.DataFrame items x 1\n",
    "            \n",
    "            \n",
    "            #print(prospected_total_utility.shape, member_weights.T.shape)\n",
    "            \n",
    "            allowed_utility_for_users = pd.DataFrame(np.dot(prospected_total_utility.values, member_weights.T.values), columns=member_weights.T.columns, index=prospected_total_utility.index)\n",
    "                                                          \n",
    "            #print(allowed_utility_for_users.shape)\n",
    "            \n",
    "            #cap the item's utility by the already assigned utility per user\n",
    "            unfulfilled_utility_for_users = allowed_utility_for_users.subtract(total_user_utility_awarded, axis=\"columns\")\n",
    "            unfulfilled_utility_for_users[unfulfilled_utility_for_users < 0] = 0 \n",
    "                                               \n",
    "            candidate_user_relevance = pd.concat([unfulfilled_utility_for_users,candidate_utility]).min(level=0)                                               \n",
    "            candidate_relevance = candidate_user_relevance.sum(axis=\"columns\")\n",
    "             \n",
    "            #remove already selected items\n",
    "            candidate_relevance = candidate_relevance.loc[~candidate_relevance.index.isin(selected_items)]\n",
    "            item_pos = candidate_relevance.argmax()\n",
    "            item_id = candidate_relevance.index[item_pos]  \n",
    "            \n",
    "            #print(item_pos,item_id,candidate_relevance[item_id])\n",
    "            \n",
    "            #print(candidate_relevance.index.difference(candidate_utility.index))\n",
    "            #print(item_id in candidate_relevance.index, item_id in candidate_utility.index)\n",
    "            selected_items.append(item_id)\n",
    "            \n",
    "            winner_row = candidate_utility.loc[item_id,:]\n",
    "            #print(winner_row)\n",
    "            #print(winner_row.shape)\n",
    "            #print(item_id,item_pos,candidate_relevance.max())\n",
    "            #print(selected_items)\n",
    "            #print(total_user_utility_awarded)\n",
    "            #print(winner_row.iloc[0,:])\n",
    "            \n",
    "            total_user_utility_awarded.loc[:] = total_user_utility_awarded.loc[:] + winner_row\n",
    "            \n",
    "            total_utility_awarded += winner_row.values.sum()\n",
    "            #print(total_user_utility_awarded)\n",
    "            #print(total_utility_awarded)\n",
    "            \n",
    "        \n",
    "        return selected_items\n",
    "    \n",
    "    def generate_group_recommendations_for_group(self, group_ratings, recommendations_number):\n",
    "        selected_items = self.ep_fuzzdhondt_algorithm( group_ratings, recommendations_number)        \n",
    "        return {\"EPFuzzDA\" : selected_items}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating recommendations for all the aggregation strategies\n",
    "\n",
    "# def generate_group_recommendations_forall_aggr_strat(test_df, group_composition, recommendations_number):\n",
    "#     group_recommendations = dict()\n",
    "#     for aggregation_strategy in cfg.aggregation_strategies:\n",
    "#         print(datetime.now(), aggregation_strategy)\n",
    "#         agg = AggregationStrategy.getAggregator(aggregation_strategy)\n",
    "#         group_recommendations[aggregation_strategy] = agg.generate_group_recommendations_forall_groups(test_df, group_composition, recommendations_number)\n",
    "        \n",
    "#     return group_recommendations\n",
    "\n",
    "def generate_group_recommendations_forall_groups(test_df, group_composition, recommendations_number):\n",
    "    group_recommendations = dict()\n",
    "    for group_id in group_composition:\n",
    "        \n",
    "#         print(datetime.now(), group_id)\n",
    "        \n",
    "        # extract group info\n",
    "        group = group_composition[group_id]\n",
    "        group_size = group['group_size']\n",
    "        group_similarity = group['group_similarity']\n",
    "        group_members = group['group_members']\n",
    "            \n",
    "        # filter ratings for the group members\n",
    "        group_ratings = test_df.loc[test_df['user'].isin(group_members)]\n",
    "        \n",
    "        group_rec = dict()\n",
    "        for aggregation_strategy in cfg.aggregation_strategies:\n",
    "#             print(datetime.now(), aggregation_strategy)\n",
    "            agg = AggregationStrategy.getAggregator(aggregation_strategy)\n",
    "            group_rec = {**group_rec, **agg.generate_group_recommendations_for_group(group_ratings, recommendations_number)}\n",
    "        \n",
    "        \n",
    "        group_recommendations[group_id] = group_rec\n",
    "        \n",
    "    return group_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing for inverse propensity weighting, \n",
    "#for more details visit https://dl.acm.org/doi/abs/10.1145/3240323.3240355\n",
    "def calculate_inverse_propensity_score(ratings_df, train_df, propensity_gama):\n",
    "    items = ratings_df[\"item\"].unique()\n",
    "    \n",
    "    #failsafe if some of the items never appeared in train data\n",
    "    propensity_per_item = pd.DataFrame(1.0, index=items, columns=[\"propensity_score\"])\n",
    "    \n",
    "    n_i_star_vector = train_df.groupby(\"item\")[\"rating\"].count()\n",
    "    P_ui_vector = n_i_star_vector**((propensity_gama+1)/2)\n",
    "    propensity_per_item.loc[P_ui_vector.index,\"propensity_score\"] = P_ui_vector\n",
    "\n",
    "        \n",
    "    return propensity_per_item   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing for inverse propensity weighting\n",
    "#Calculating  per-user fixed term of 1/\\sum_{i \\in R_u}(1/P_{u,i}), \n",
    "#    where R_u is a list of items known by user u and P_{u,i} is their propensity score\n",
    "def calculate_inverse_propensity_score_user_normalization(propensity_per_item, test_df):\n",
    "    inverse_propensity = 1/propensity_per_item\n",
    "    \n",
    "    local_df = test_df.copy()\n",
    "    local_df = local_df.join(inverse_propensity, on=\"item\")\n",
    "    \n",
    "    per_user_normalization_term = 1/local_df.groupby(\"user\")[\"propensity_score\"].sum()\n",
    "        \n",
    "    return per_user_normalization_term "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Evaluation Metrics strategies\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class MetricEvaluator(ABC):\n",
    "    \n",
    "    @staticmethod\n",
    "    def getMetricEvaluator(metric):            \n",
    "        if metric==\"NDCG\":\n",
    "            return NDCGEvaluator()\n",
    "        elif metric==\"DCG\":\n",
    "            return DCGEvaluator()\n",
    "        elif metric==\"BINARY\":\n",
    "            return BinaryEvaluator()        \n",
    "        elif metric==\"BASE\":\n",
    "            return BaselinesEvaluators()\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    @abstractmethod\n",
    "    def evaluateGroupRecommendation(self, group_ground_truth, group_recommendation, group_members):\n",
    "        pass\n",
    "    \n",
    "\n",
    "class NDCGEvaluator(MetricEvaluator):\n",
    "    \n",
    "    def evaluateUserNDCG(self, user_ground_truth, group_recommendation, user_norm):\n",
    "        # note that both dcg and idcg should be element-wise normalized via per_user_propensity_normalization_term\n",
    "        # therefore, it can be excluded from calculations        \n",
    "        dcg = 0\n",
    "#         display(user_ground_truth)\n",
    "#         display(group_recommendation)\n",
    "        for k, item in enumerate(group_recommendation):\n",
    "            dcg = dcg + ((user_ground_truth.loc[item,\"final_rating\"] if item in user_ground_truth.index else 0) / np.log2(k+2))\n",
    "        \n",
    "        idcg = 0\n",
    "        # what if intersection is empty?\n",
    "        user_ground_truth.sort_values(\"final_rating\", inplace=True, ascending=False)\n",
    "        #print(user_ground_truth)\n",
    "        #print(len(user_ground_truth),len(group_recommendation),min(len(user_ground_truth),len(group_recommendation)))\n",
    "        for k in range(min(len(user_ground_truth),len(group_recommendation))):\n",
    "            idcg = idcg + (user_ground_truth.iloc[k][\"final_rating\"] / np.log2(k+2))\n",
    "        if idcg > 0:    \n",
    "            ndcg = dcg / idcg\n",
    "        else:\n",
    "            ndcg = 0\n",
    "        \n",
    "        return ndcg, user_norm*dcg\n",
    "        \n",
    "    def evaluateGroupRecommendation(self, group_ground_truth, group_recommendation, group_members):\n",
    "        ndcg_list = list()\n",
    "        dcg_list = list()\n",
    "        for user in group_members:\n",
    "\n",
    "            user_ground_truth = ground_truth.loc[ground_truth['user']==user]        \n",
    "            user_ground_truth.set_index(\"item\", inplace=True)\n",
    "            \n",
    "            # basic polarity debiasing (max(0, rating + c))\n",
    "            if cfg.feedback_polarity_debiasing != 0.0:\n",
    "                user_ground_truth[\"final_rating\"] = user_ground_truth.loc[:,\"rating\"] + cfg.feedback_polarity_debiasing\n",
    "                user_ground_truth.loc[user_ground_truth.final_rating < 0,\"final_rating\"] = 0            \n",
    "            # feedback binarization\n",
    "            elif cfg.binarize_feedback == True:\n",
    "                user_ground_truth[\"final_rating\"] = 0\n",
    "                user_ground_truth.loc[user_ground_truth.rating >= cfg.binarize_feedback_positive_threshold,\"final_rating\"] = 1\n",
    "            # no modifications to feedback\n",
    "            else:\n",
    "                user_ground_truth[\"final_rating\"] = user_ground_truth[\"rating\"]            \n",
    "            \n",
    "            #inverse propensity weighting of items\n",
    "            user_ground_truth.loc[:,\"final_rating\"] = user_ground_truth.loc[:,\"final_rating\"] / propensity_per_item[\"propensity_score\"]\n",
    "            #inverse propensity per-user normalization\n",
    "            user_norm = 1.0\n",
    "            if per_user_propensity_normalization_term is not None:\n",
    "                user_norm = per_user_propensity_normalization_term[user]            \n",
    "            \n",
    "            ndcg_user, dcg_user = self.evaluateUserNDCG(user_ground_truth, group_recommendation, user_norm)\n",
    "            ndcg_list.append(ndcg_user)\n",
    "            dcg_list.append(dcg_user)\n",
    "            \n",
    "            #failsafe for all negative results\n",
    "            if np.amax(ndcg_list) > 0:\n",
    "                ndcg_min_max = np.amin(ndcg_list)/np.amax(ndcg_list)\n",
    "                dcg_min_max = np.amin(dcg_list)/np.amax(dcg_list)\n",
    "            else:\n",
    "                ndcg_min_max = 0.0\n",
    "                dcg_min_max = 0.0\n",
    "        return [\n",
    "            {\n",
    "                \"metric\" : \"NDCG\",\n",
    "                \"aggr_metric\" : \"mean\",\n",
    "                \"value\" : np.mean(ndcg_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"NDCG\",\n",
    "                \"aggr_metric\" : \"min\",\n",
    "                \"value\" : np.amin(ndcg_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"NDCG\",\n",
    "                \"aggr_metric\" : \"minmax\",\n",
    "                \"value\" : ndcg_min_max\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"DCG\",\n",
    "                \"aggr_metric\" : \"mean\",\n",
    "                \"value\" : np.mean(dcg_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"DCG\",\n",
    "                \"aggr_metric\" : \"min\",\n",
    "                \"value\" : np.amin(dcg_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"DCG\",\n",
    "                \"aggr_metric\" : \"minmax\",\n",
    "                \"value\" : dcg_min_max\n",
    "            }            \n",
    "        ]\n",
    "\n",
    "    \n",
    "class BinaryEvaluator(MetricEvaluator):\n",
    "    \n",
    "    def evaluateUserBinary(self, user_ground_truth, group_recommendation, user_norm):     \n",
    "        correct_recs_list = user_ground_truth.loc[(user_ground_truth.index.isin(group_recommendation))&(user_ground_truth.final_rating > 0)]\n",
    "        correct_recs = correct_recs_list.shape[0]\n",
    "        all_correct_per_user = user_ground_truth.loc[user_ground_truth.final_rating > 0].shape[0]\n",
    "        if all_correct_per_user == 0:\n",
    "            return (0.0,0.0,0.0)\n",
    "        recall = user_norm * correct_recs / all_correct_per_user\n",
    "        \n",
    "        #bounded recall, denominator is min(# of relevant items, length of the list)\n",
    "        all_correct_per_user_caped = min([all_correct_per_user,len(group_recommendation)])\n",
    "        bounded_recall = user_norm * correct_recs / all_correct_per_user_caped\n",
    "        \n",
    "        #discounted first hit\n",
    "        if correct_recs == 0:\n",
    "            dfh = 0.0\n",
    "        else:\n",
    "            for k,item in enumerate(group_recommendation):\n",
    "                if item in correct_recs_list.index:\n",
    "                    first_hit_rank = k\n",
    "                    break\n",
    "            dfh = user_norm * 1 / np.log2(first_hit_rank+2)   \n",
    "                                    \n",
    "        \n",
    "        return (recall, bounded_recall, dfh)\n",
    "        \n",
    "        \n",
    "    def evaluateGroupRecommendation(self, group_ground_truth, group_recommendation, group_members):\n",
    "        #Irrespective of the cfg.binarize_feedback setting, we need binary feedback for this set of metrics\n",
    "        #Use binary_positive_threshold, but do not use polarity_debiasing (kind of does the same thing)\n",
    "        recall_list = list()\n",
    "        bounded_recall_list = list()\n",
    "        dfh_list = list()\n",
    "        zero_recall = 0\n",
    "        for user in group_members:\n",
    "            user_ground_truth = ground_truth.loc[ground_truth['user']==user]          \n",
    "            user_ground_truth.set_index(\"item\", inplace=True)            \n",
    "            \n",
    "            #feedback binarization\n",
    "            user_ground_truth[\"final_rating\"] = 0\n",
    "            user_ground_truth.loc[user_ground_truth.rating >= cfg.binarize_feedback_positive_threshold,\"final_rating\"] = 1\n",
    "                \n",
    "            #self-normalized inverse propensity debiasing\n",
    "            user_ground_truth.loc[:,\"final_rating\"] = user_ground_truth.loc[:,\"final_rating\"] / propensity_per_item[\"propensity_score\"]\n",
    "            user_norm = 1.0\n",
    "            if per_user_propensity_normalization_term is not None:\n",
    "                user_norm = per_user_propensity_normalization_term[user]\n",
    "            \n",
    "            recall_user, bounded_recall_user, dfh_user = self.evaluateUserBinary(user_ground_truth, group_recommendation, user_norm)\n",
    "            if recall_user == 0:                \n",
    "                zero_recall +=  1\n",
    "\n",
    "            recall_list.append(recall_user)\n",
    "            bounded_recall_list.append(bounded_recall_user)\n",
    "            dfh_list.append(dfh_user)\n",
    "            \n",
    "        #failsafe for all negative results\n",
    "        if np.amax(recall_list) > 0:\n",
    "            rec_min_max = np.amin(recall_list)/np.amax(recall_list)\n",
    "            bound_min_max = np.amin(bounded_recall_list)/np.amax(bounded_recall_list)\n",
    "            dfh_min_max = np.amin(dfh_list)/np.amax(dfh_list)\n",
    "        else:\n",
    "            rec_min_max = 0.0\n",
    "            bound_min_max = 0.0\n",
    "            dfh_min_max = 0.0\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                \"metric\" : \"Recall\",\n",
    "                \"aggr_metric\" : \"mean\",\n",
    "                \"value\" : np.mean(recall_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"Recall\",\n",
    "                \"aggr_metric\" : \"min\",\n",
    "                \"value\" : np.amin(recall_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"Recall\",\n",
    "                \"aggr_metric\" : \"minmax\",\n",
    "                \"value\" : rec_min_max\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"BoundedRecall\",\n",
    "                \"aggr_metric\" : \"mean\",\n",
    "                \"value\" : np.mean(bounded_recall_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"BoundedRecall\",\n",
    "                \"aggr_metric\" : \"min\",\n",
    "                \"value\" : np.amin(bounded_recall_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"BoundedRecall\",\n",
    "                \"aggr_metric\" : \"minmax\",\n",
    "                \"value\" : bound_min_max\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"DFH\",\n",
    "                \"aggr_metric\" : \"mean\",\n",
    "                \"value\" : np.mean(dfh_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"DFH\",\n",
    "                \"aggr_metric\" : \"min\",\n",
    "                \"value\" : np.amin(dfh_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"DFH\",\n",
    "                \"aggr_metric\" : \"minmax\",\n",
    "                \"value\" : dfh_min_max\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"zRecall\",\n",
    "                \"aggr_metric\" : \"none\",\n",
    "                \"value\" : zero_recall / len(group_members)\n",
    "            }\n",
    "        ]            \n",
    "    \n",
    "\n",
    "\n",
    "class BaselinesEvaluators(MetricEvaluator):\n",
    "    def evaluateGroupRecommendation(self, group_ground_truth, group_recommendation, group_members):\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_group_recommendations_forall_groups(ground_truth, group_recommendations, group_composition, current_fold):\n",
    "#     group_evaluations = dict()\n",
    "    group_evaluations = list()\n",
    "    for group_id in group_composition:\n",
    "        \n",
    "        #print(datetime.now(), group_id)\n",
    "        \n",
    "        # extract group info\n",
    "        group = group_composition[group_id]\n",
    "        group_size = group['group_size']\n",
    "        group_similarity = group['group_similarity']\n",
    "        group_members = group['group_members']\n",
    "        group_rec = group_recommendations[group_id]\n",
    "            \n",
    "        # filter ratings in ground_truth for the group members\n",
    "        group_ground_truth = ground_truth.loc[ground_truth['user'].isin(group_members)]\n",
    "        \n",
    "\n",
    "        for aggregation_strategy in group_rec:\n",
    "            agg_group_rec = group_rec[aggregation_strategy]\n",
    "            agg_group_rec_eval = list()\n",
    "            for metric in cfg.metrics:\n",
    "    #             print(datetime.now(), aggregation_strategy)\n",
    "                metric_evaluator = MetricEvaluator.getMetricEvaluator(metric)\n",
    "#                 agg_group_rec_eval = {**agg_group_rec_eval, **metric_evaluator.evaluateGroupRecommendation(group_ground_truth, agg_group_rec, group_members)}\n",
    "                agg_group_rec_eval = agg_group_rec_eval + metric_evaluator.evaluateGroupRecommendation(group_ground_truth, agg_group_rec, group_members)\n",
    "    \n",
    "            # Adding aggregation strategy info\n",
    "            for row in agg_group_rec_eval:\n",
    "                row['aggregation_strategy'] = aggregation_strategy\n",
    "                row['group_id'] = group_id\n",
    "                row['current_fold'] = current_fold\n",
    "#             group_rec_eval[aggregation_strategy] = agg_group_rec_eval\n",
    "        \n",
    "            #print(agg_group_rec_eval)\n",
    "            group_evaluations = group_evaluations + agg_group_rec_eval\n",
    "        # Adding group_id info\n",
    "#         group_evaluations[group_id] = group_rec_eval\n",
    "        \n",
    "    return group_evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-14 15:58:46.156261 Creating folds\n",
      "2022-09-14 15:58:46.156261 Folds created!\n",
      ">>> Start processing fold: Train 753780 Test: 188445\n",
      "2022-09-14 15:58:58.035916 Train individual RS and get predictions\n",
      "LENSKIT_CF_ITEM\n",
      "training\n",
      "evaluating predictions\n",
      "Done!\n",
      "2022-09-14 16:00:26.832698 Generate GRS for all the aggregation strategies and all the groups\n",
      "2022-09-14 16:00:41.670468 0\n",
      "2022-09-14 16:00:41.735091 1\n",
      "2022-09-14 16:00:41.804876 2\n",
      "2022-09-14 16:00:41.876551 3\n",
      "2022-09-14 16:00:41.947198 4\n",
      "2022-09-14 16:00:42.013765 5\n",
      "2022-09-14 16:00:42.069407 6\n",
      "2022-09-14 16:00:42.130947 7\n",
      "2022-09-14 16:00:42.201578 8\n",
      "2022-09-14 16:00:42.257174 9\n",
      "2022-09-14 16:00:42.326804 10\n",
      "2022-09-14 16:00:42.392333 11\n",
      "2022-09-14 16:00:42.453870 12\n",
      "2022-09-14 16:00:42.524632 13\n",
      "2022-09-14 16:00:42.587144 14\n",
      "2022-09-14 16:00:42.649706 15\n",
      "2022-09-14 16:00:42.706307 16\n",
      "2022-09-14 16:00:42.768873 17\n",
      "2022-09-14 16:00:42.822330 18\n",
      "2022-09-14 16:00:42.892942 19\n",
      "2022-09-14 16:00:42.958573 20\n",
      "2022-09-14 16:00:43.095813 21\n",
      "2022-09-14 16:00:43.223929 22\n",
      "2022-09-14 16:00:43.353188 23\n",
      "2022-09-14 16:00:43.474545 24\n",
      "2022-09-14 16:00:43.608277 25\n",
      "2022-09-14 16:00:43.735517 26\n",
      "2022-09-14 16:00:43.859606 27\n",
      "2022-09-14 16:00:43.979811 28\n",
      "2022-09-14 16:00:44.106943 29\n",
      "2022-09-14 16:00:44.236135 30\n",
      "2022-09-14 16:00:44.367288 31\n",
      "2022-09-14 16:00:44.493469 32\n",
      "2022-09-14 16:00:44.633081 33\n",
      "2022-09-14 16:00:44.763326 34\n",
      "2022-09-14 16:00:44.894766 35\n",
      "2022-09-14 16:00:45.026936 36\n",
      "2022-09-14 16:00:45.153994 37\n",
      "2022-09-14 16:00:45.288474 38\n",
      "2022-09-14 16:00:45.415962 39\n",
      "2022-09-14 16:00:45.538320 40\n",
      "2022-09-14 16:00:45.799119 41\n",
      "2022-09-14 16:00:46.068908 42\n",
      "2022-09-14 16:00:46.323495 43\n",
      "2022-09-14 16:00:46.577542 44\n",
      "2022-09-14 16:00:46.842005 45\n",
      "2022-09-14 16:00:47.079589 46\n",
      "2022-09-14 16:00:47.338213 47\n",
      "2022-09-14 16:00:47.596033 48\n",
      "2022-09-14 16:00:47.849771 49\n",
      "2022-09-14 16:00:48.106527 50\n",
      "2022-09-14 16:00:48.358218 51\n",
      "2022-09-14 16:00:48.594611 52\n",
      "2022-09-14 16:00:48.856472 53\n",
      "2022-09-14 16:00:49.101008 54\n",
      "2022-09-14 16:00:49.358716 55\n",
      "2022-09-14 16:00:49.632640 56\n",
      "2022-09-14 16:00:49.873446 57\n",
      "2022-09-14 16:00:50.130193 58\n",
      "2022-09-14 16:00:50.408245 59\n",
      "2022-09-14 16:00:50.666092 Fold Evaluation DONE\n",
      ">>> Start processing fold: Train 753780 Test: 188445\n",
      "2022-09-14 16:00:57.978535 Train individual RS and get predictions\n",
      "LENSKIT_CF_ITEM\n",
      "training\n",
      "evaluating predictions\n",
      "Done!\n",
      "2022-09-14 16:02:26.501545 Generate GRS for all the aggregation strategies and all the groups\n",
      "2022-09-14 16:02:42.850581 0\n",
      "2022-09-14 16:02:42.918523 1\n",
      "2022-09-14 16:02:43.001453 2\n",
      "2022-09-14 16:02:43.077249 3\n",
      "2022-09-14 16:02:43.153229 4\n",
      "2022-09-14 16:02:43.224040 5\n",
      "2022-09-14 16:02:43.285874 6\n",
      "2022-09-14 16:02:43.401565 7\n",
      "2022-09-14 16:02:43.490329 8\n",
      "2022-09-14 16:02:43.550019 9\n",
      "2022-09-14 16:02:43.623752 10\n",
      "2022-09-14 16:02:43.693198 11\n",
      "2022-09-14 16:02:43.754309 12\n",
      "2022-09-14 16:02:43.826203 13\n",
      "2022-09-14 16:02:43.889825 14\n",
      "2022-09-14 16:02:43.953433 15\n",
      "2022-09-14 16:02:44.016771 16\n",
      "2022-09-14 16:02:44.081477 17\n",
      "2022-09-14 16:02:44.134965 18\n",
      "2022-09-14 16:02:44.209199 19\n",
      "2022-09-14 16:02:44.276021 20\n",
      "2022-09-14 16:02:44.419947 21\n",
      "2022-09-14 16:02:44.556790 22\n",
      "2022-09-14 16:02:44.697228 23\n",
      "2022-09-14 16:02:44.833875 24\n",
      "2022-09-14 16:02:44.979485 25\n",
      "2022-09-14 16:02:45.109485 26\n",
      "2022-09-14 16:02:45.237048 27\n",
      "2022-09-14 16:02:45.356496 28\n",
      "2022-09-14 16:02:45.484731 29\n",
      "2022-09-14 16:02:45.619152 30\n",
      "2022-09-14 16:02:45.752816 31\n",
      "2022-09-14 16:02:45.918379 32\n",
      "2022-09-14 16:02:46.112583 33\n",
      "2022-09-14 16:02:46.245827 34\n",
      "2022-09-14 16:02:46.380762 35\n",
      "2022-09-14 16:02:46.516081 36\n",
      "2022-09-14 16:02:46.656705 37\n",
      "2022-09-14 16:02:46.792697 38\n",
      "2022-09-14 16:02:46.922745 39\n",
      "2022-09-14 16:02:47.053274 40\n",
      "2022-09-14 16:02:47.328361 41\n",
      "2022-09-14 16:02:47.643667 42\n",
      "2022-09-14 16:02:47.931208 43\n",
      "2022-09-14 16:02:48.209662 44\n",
      "2022-09-14 16:02:48.468350 45\n",
      "2022-09-14 16:02:48.759950 46\n",
      "2022-09-14 16:02:49.024620 47\n",
      "2022-09-14 16:02:49.298115 48\n",
      "2022-09-14 16:02:49.591214 49\n",
      "2022-09-14 16:02:49.851272 50\n",
      "2022-09-14 16:02:50.111915 51\n",
      "2022-09-14 16:02:50.386287 52\n",
      "2022-09-14 16:02:50.658620 53\n",
      "2022-09-14 16:02:50.935687 54\n",
      "2022-09-14 16:02:51.193407 55\n",
      "2022-09-14 16:02:51.478085 56\n",
      "2022-09-14 16:02:51.724360 57\n",
      "2022-09-14 16:02:52.028237 58\n",
      "2022-09-14 16:02:52.291534 59\n",
      "2022-09-14 16:02:52.548173 Fold Evaluation DONE\n",
      ">>> Start processing fold: Train 753780 Test: 188445\n",
      "2022-09-14 16:03:00.027901 Train individual RS and get predictions\n",
      "LENSKIT_CF_ITEM\n",
      "training\n",
      "evaluating predictions\n",
      "Done!\n",
      "2022-09-14 16:04:29.379651 Generate GRS for all the aggregation strategies and all the groups\n",
      "2022-09-14 16:04:44.654062 0\n",
      "2022-09-14 16:04:44.718976 1\n",
      "2022-09-14 16:04:44.790644 2\n",
      "2022-09-14 16:04:44.864513 3\n",
      "2022-09-14 16:04:44.948506 4\n",
      "2022-09-14 16:04:45.023310 5\n",
      "2022-09-14 16:04:45.082153 6\n",
      "2022-09-14 16:04:45.146684 7\n",
      "2022-09-14 16:04:45.219811 8\n",
      "2022-09-14 16:04:45.274609 9\n",
      "2022-09-14 16:04:45.347478 10\n",
      "2022-09-14 16:04:45.414278 11\n",
      "2022-09-14 16:04:45.483309 12\n",
      "2022-09-14 16:04:45.564097 13\n",
      "2022-09-14 16:04:45.634903 14\n",
      "2022-09-14 16:04:45.703690 15\n",
      "2022-09-14 16:04:45.759330 16\n",
      "2022-09-14 16:04:45.821911 17\n",
      "2022-09-14 16:04:45.875606 18\n",
      "2022-09-14 16:04:45.946429 19\n",
      "2022-09-14 16:04:46.010773 20\n",
      "2022-09-14 16:04:46.151253 21\n",
      "2022-09-14 16:04:46.279678 22\n",
      "2022-09-14 16:04:46.414202 23\n",
      "2022-09-14 16:04:46.541003 24\n",
      "2022-09-14 16:04:46.683727 25\n",
      "2022-09-14 16:04:46.819365 26\n",
      "2022-09-14 16:04:46.954027 27\n",
      "2022-09-14 16:04:47.075447 28\n",
      "2022-09-14 16:04:47.206518 29\n",
      "2022-09-14 16:04:47.338034 30\n",
      "2022-09-14 16:04:47.466206 31\n",
      "2022-09-14 16:04:47.593381 32\n",
      "2022-09-14 16:04:47.731797 33\n",
      "2022-09-14 16:04:47.862079 34\n",
      "2022-09-14 16:04:47.995532 35\n",
      "2022-09-14 16:04:48.124906 36\n",
      "2022-09-14 16:04:48.251228 37\n",
      "2022-09-14 16:04:48.384740 38\n",
      "2022-09-14 16:04:48.511873 39\n",
      "2022-09-14 16:04:48.636341 40\n",
      "2022-09-14 16:04:48.890996 41\n",
      "2022-09-14 16:04:49.157733 42\n",
      "2022-09-14 16:04:49.412235 43\n",
      "2022-09-14 16:04:49.667022 44\n",
      "2022-09-14 16:04:49.926681 45\n",
      "2022-09-14 16:04:50.164054 46\n",
      "2022-09-14 16:04:50.419566 47\n",
      "2022-09-14 16:04:50.677219 48\n",
      "2022-09-14 16:04:50.928387 49\n",
      "2022-09-14 16:04:51.192021 50\n",
      "2022-09-14 16:04:51.451903 51\n",
      "2022-09-14 16:04:51.691133 52\n",
      "2022-09-14 16:04:51.952754 53\n",
      "2022-09-14 16:04:52.198422 54\n",
      "2022-09-14 16:04:52.451052 55\n",
      "2022-09-14 16:04:52.719386 56\n",
      "2022-09-14 16:04:52.957967 57\n",
      "2022-09-14 16:04:53.215730 58\n",
      "2022-09-14 16:04:53.475437 59\n",
      "2022-09-14 16:04:53.731129 Fold Evaluation DONE\n",
      ">>> Start processing fold: Train 753780 Test: 188445\n",
      "2022-09-14 16:05:01.083159 Train individual RS and get predictions\n",
      "LENSKIT_CF_ITEM\n",
      "training\n",
      "evaluating predictions\n",
      "Done!\n",
      "2022-09-14 16:06:29.666738 Generate GRS for all the aggregation strategies and all the groups\n",
      "2022-09-14 16:06:44.637212 0\n",
      "2022-09-14 16:06:44.701689 1\n",
      "2022-09-14 16:06:44.772342 2\n",
      "2022-09-14 16:06:44.842000 3\n",
      "2022-09-14 16:06:44.912802 4\n",
      "2022-09-14 16:06:44.978458 5\n",
      "2022-09-14 16:06:45.031869 6\n",
      "2022-09-14 16:06:45.094457 7\n",
      "2022-09-14 16:06:45.166721 8\n",
      "2022-09-14 16:06:45.221172 9\n",
      "2022-09-14 16:06:45.290864 10\n",
      "2022-09-14 16:06:45.356450 11\n",
      "2022-09-14 16:06:45.418133 12\n",
      "2022-09-14 16:06:45.489754 13\n",
      "2022-09-14 16:06:45.552389 14\n",
      "2022-09-14 16:06:45.615261 15\n",
      "2022-09-14 16:06:45.670724 16\n",
      "2022-09-14 16:06:45.733304 17\n",
      "2022-09-14 16:06:45.786970 18\n",
      "2022-09-14 16:06:45.856600 19\n",
      "2022-09-14 16:06:45.920164 20\n",
      "2022-09-14 16:06:46.057352 21\n",
      "2022-09-14 16:06:46.187614 22\n",
      "2022-09-14 16:06:46.319843 23\n",
      "2022-09-14 16:06:46.441557 24\n",
      "2022-09-14 16:06:46.580021 25\n",
      "2022-09-14 16:06:46.707175 26\n",
      "2022-09-14 16:06:46.832233 27\n",
      "2022-09-14 16:06:46.951220 28\n",
      "2022-09-14 16:06:47.077311 29\n",
      "2022-09-14 16:06:47.207435 30\n",
      "2022-09-14 16:06:47.331563 31\n",
      "2022-09-14 16:06:47.457720 32\n",
      "2022-09-14 16:06:47.599057 33\n",
      "2022-09-14 16:06:47.730614 34\n",
      "2022-09-14 16:06:47.864074 35\n",
      "2022-09-14 16:06:47.996337 36\n",
      "2022-09-14 16:06:48.126766 37\n",
      "2022-09-14 16:06:48.260066 38\n",
      "2022-09-14 16:06:48.386311 39\n",
      "2022-09-14 16:06:48.507414 40\n",
      "2022-09-14 16:06:48.766234 41\n",
      "2022-09-14 16:06:49.029957 42\n",
      "2022-09-14 16:06:49.289181 43\n",
      "2022-09-14 16:06:49.548195 44\n",
      "2022-09-14 16:06:49.807128 45\n",
      "2022-09-14 16:06:50.043012 46\n",
      "2022-09-14 16:06:50.305287 47\n",
      "2022-09-14 16:06:50.560414 48\n",
      "2022-09-14 16:06:50.810679 49\n",
      "2022-09-14 16:06:51.068006 50\n",
      "2022-09-14 16:06:51.321246 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-14 16:06:51.559416 52\n",
      "2022-09-14 16:06:51.833747 53\n",
      "2022-09-14 16:06:52.077962 54\n",
      "2022-09-14 16:06:52.329252 55\n",
      "2022-09-14 16:06:52.594346 56\n",
      "2022-09-14 16:06:52.835606 57\n",
      "2022-09-14 16:06:53.091844 58\n",
      "2022-09-14 16:06:53.354936 59\n",
      "2022-09-14 16:06:53.612584 Fold Evaluation DONE\n",
      ">>> Start processing fold: Train 753780 Test: 188445\n",
      "2022-09-14 16:07:00.938600 Train individual RS and get predictions\n",
      "LENSKIT_CF_ITEM\n",
      "training\n",
      "evaluating predictions\n",
      "Done!\n",
      "2022-09-14 16:08:28.835704 Generate GRS for all the aggregation strategies and all the groups\n",
      "2022-09-14 16:08:44.064236 0\n",
      "2022-09-14 16:08:44.127983 1\n",
      "2022-09-14 16:08:44.201753 2\n",
      "2022-09-14 16:08:44.273578 3\n",
      "2022-09-14 16:08:44.344336 4\n",
      "2022-09-14 16:08:44.410052 5\n",
      "2022-09-14 16:08:44.463594 6\n",
      "2022-09-14 16:08:44.526362 7\n",
      "2022-09-14 16:08:44.599067 8\n",
      "2022-09-14 16:08:44.654559 9\n",
      "2022-09-14 16:08:44.726008 10\n",
      "2022-09-14 16:08:44.790592 11\n",
      "2022-09-14 16:08:44.852191 12\n",
      "2022-09-14 16:08:44.923942 13\n",
      "2022-09-14 16:08:44.985653 14\n",
      "2022-09-14 16:08:45.049259 15\n",
      "2022-09-14 16:08:45.119260 16\n",
      "2022-09-14 16:08:45.188010 17\n",
      "2022-09-14 16:08:45.242573 18\n",
      "2022-09-14 16:08:45.312343 19\n",
      "2022-09-14 16:08:45.377085 20\n",
      "2022-09-14 16:08:45.513385 21\n",
      "2022-09-14 16:08:45.643656 22\n",
      "2022-09-14 16:08:45.774029 23\n",
      "2022-09-14 16:08:45.893819 24\n",
      "2022-09-14 16:08:46.026088 25\n",
      "2022-09-14 16:08:46.154268 26\n",
      "2022-09-14 16:08:46.281841 27\n",
      "2022-09-14 16:08:46.403240 28\n",
      "2022-09-14 16:08:46.527664 29\n",
      "2022-09-14 16:08:46.659092 30\n",
      "2022-09-14 16:08:46.784292 31\n",
      "2022-09-14 16:08:46.911606 32\n",
      "2022-09-14 16:08:47.049133 33\n",
      "2022-09-14 16:08:47.179568 34\n",
      "2022-09-14 16:08:47.312021 35\n",
      "2022-09-14 16:08:47.443383 36\n",
      "2022-09-14 16:08:47.567841 37\n",
      "2022-09-14 16:08:47.702279 38\n",
      "2022-09-14 16:08:47.827594 39\n",
      "2022-09-14 16:08:47.949854 40\n",
      "2022-09-14 16:08:48.207175 41\n",
      "2022-09-14 16:08:48.474992 42\n",
      "2022-09-14 16:08:48.730531 43\n",
      "2022-09-14 16:08:48.983504 44\n",
      "2022-09-14 16:08:49.241244 45\n",
      "2022-09-14 16:08:49.478355 46\n",
      "2022-09-14 16:08:49.734982 47\n",
      "2022-09-14 16:08:49.988610 48\n",
      "2022-09-14 16:08:50.237049 49\n",
      "2022-09-14 16:08:50.495921 50\n",
      "2022-09-14 16:08:50.749989 51\n",
      "2022-09-14 16:08:50.989476 52\n",
      "2022-09-14 16:08:51.254124 53\n",
      "2022-09-14 16:08:51.498691 54\n",
      "2022-09-14 16:08:51.753071 55\n",
      "2022-09-14 16:08:52.019404 56\n",
      "2022-09-14 16:08:52.261166 57\n",
      "2022-09-14 16:08:52.518004 58\n",
      "2022-09-14 16:08:52.779646 59\n",
      "2022-09-14 16:08:53.033089 Fold Evaluation DONE\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# General pipeline\n",
    "\n",
    "# creating train-test folds\n",
    "# split stratified on the users \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import itertools\n",
    "\n",
    "print(datetime.now(), \"Creating folds\")\n",
    "# skf = StratifiedKFold(n_splits=group_rs_evaluation_folds_k, random_state=None, shuffle=True)\n",
    "skf = StratifiedKFold(n_splits=group_rs_evaluation_folds_k, random_state=None, shuffle=True)\n",
    "\n",
    "print(datetime.now(), \"Folds created!\")\n",
    "current_fold = 0\n",
    "evaluations = list()\n",
    "for train_index, test_index in skf.split(ratings_df, ratings_df['user']):\n",
    "    print(\">>> Start processing fold: Train\", len(train_index), \"Test:\", len(test_index))\n",
    "    \n",
    "    # split train and test df\n",
    "    train_df = ratings_df.iloc[train_index]\n",
    "    test_df = ratings_df.iloc[test_index]\n",
    "    \n",
    "    # getting user-items pairs in the training set\n",
    "    train_set_pairs = set(list(zip(train_df['user'].values,train_df['item'].values)))\n",
    "    \n",
    "    # create test_complete_df with all the possible user-items pairs in the test_df\n",
    "    user_set = set(test_df['user'].values)\n",
    "    item_set = set(test_df['item'].values)\n",
    "    all_ui_values = list(itertools.product(user_set, item_set))\n",
    "    test_pred_df = pd.DataFrame(all_ui_values, columns=['user', 'item'])\n",
    "    \n",
    "#     print(datetime.now(), \"Extended test df\")\n",
    "#     display(test_pred_df)\n",
    "    \n",
    "    print(datetime.now(), \"Train individual RS and get predictions\")\n",
    "    # train individual rs and get predictions\n",
    "    test_pred_df = train_individual_rs_and_get_predictions(train_df, test_pred_df)\n",
    "    \n",
    "    #correction for train set records (assuming repeated recommendations provide no value, therefore predicted_rating=0)\n",
    "    train_set_pairs = train_set_pairs.intersection(set(all_ui_values))\n",
    "    test_pred_df.set_index([\"user\",\"item\"], inplace=True)\n",
    "    test_pred_df.loc[train_set_pairs,\"predicted_rating\"] = 0.0\n",
    "    test_pred_df.reset_index(inplace=True)\n",
    "\n",
    "    print(datetime.now(), \"Generate GRS for all the aggregation strategies and all the groups\")\n",
    "    # - generate the recommendations for all the aggregation strategies and all the groups\n",
    "    group_recommendations = generate_group_recommendations_forall_groups(test_pred_df, group_composition, cfg.recommendations_number)\n",
    "    \n",
    "    # - evaluate the recommendations\n",
    "    if cfg.evaluation_strategy == \"COUPLED\":\n",
    "        ground_truth = test_df\n",
    "    else:\n",
    "        ground_truth = test_pred_df.rename(columns={\"predicted_rating\": \"rating\"}, errors=\"raise\")\n",
    "    \n",
    "    if cfg.inverse_propensity_debiasing == True and cfg.evaluation_strategy == \"COUPLED\":\n",
    "        propensity_per_item = calculate_inverse_propensity_score(ratings_df, train_df, cfg.inverse_propensity_gamma)\n",
    "        per_user_propensity_normalization_term = calculate_inverse_propensity_score_user_normalization(propensity_per_item, test_df)\n",
    "    else:\n",
    "        #dummies to simplify downstream code\n",
    "        propensity_per_item = pd.Series({\"propensity_score\":1.0})\n",
    "        per_user_propensity_normalization_term = None\n",
    "\n",
    "    fold_group_evaluations = evaluate_group_recommendations_forall_groups(ground_truth, group_recommendations, group_composition, current_fold)\n",
    "    print(datetime.now(), \"Fold Evaluation DONE\")\n",
    "    #display(fold_group_evaluations)\n",
    "    \n",
    "    evaluations = evaluations + fold_group_evaluations\n",
    "    current_fold = current_fold + 1\n",
    "    \n",
    "# Finally, we merge the results for all the folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(evaluations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>aggr_metric</th>\n",
       "      <th>value</th>\n",
       "      <th>aggregation_strategy</th>\n",
       "      <th>group_id</th>\n",
       "      <th>current_fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.083651</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>min</td>\n",
       "      <td>0.054949</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>minmax</td>\n",
       "      <td>0.489071</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DCG</td>\n",
       "      <td>mean</td>\n",
       "      <td>2.600710</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DCG</td>\n",
       "      <td>min</td>\n",
       "      <td>2.493450</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28795</th>\n",
       "      <td>BoundedRecall</td>\n",
       "      <td>minmax</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28796</th>\n",
       "      <td>DFH</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.070125</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28797</th>\n",
       "      <td>DFH</td>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28798</th>\n",
       "      <td>DFH</td>\n",
       "      <td>minmax</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28799</th>\n",
       "      <td>zRecall</td>\n",
       "      <td>none</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28800 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              metric aggr_metric     value aggregation_strategy  group_id  \\\n",
       "0               NDCG        mean  0.083651                  ADD         0   \n",
       "1               NDCG         min  0.054949                  ADD         0   \n",
       "2               NDCG      minmax  0.489071                  ADD         0   \n",
       "3                DCG        mean  2.600710                  ADD         0   \n",
       "4                DCG         min  2.493450                  ADD         0   \n",
       "...              ...         ...       ...                  ...       ...   \n",
       "28795  BoundedRecall      minmax  0.000000             EPFuzzDA        59   \n",
       "28796            DFH        mean  0.070125             EPFuzzDA        59   \n",
       "28797            DFH         min  0.000000             EPFuzzDA        59   \n",
       "28798            DFH      minmax  0.000000             EPFuzzDA        59   \n",
       "28799        zRecall        none  0.750000             EPFuzzDA        59   \n",
       "\n",
       "       current_fold  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "28795             4  \n",
       "28796             4  \n",
       "28797             4  \n",
       "28798             4  \n",
       "28799             4  \n",
       "\n",
       "[28800 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame.from_records(evaluations)\n",
    "display(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_folds = eval_df.groupby(['metric', 'aggr_metric', 'aggregation_strategy', 'group_id']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>aggr_metric</th>\n",
       "      <th>aggregation_strategy</th>\n",
       "      <th>group_id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BoundedRecall</td>\n",
       "      <td>mean</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>BoundedRecall</td>\n",
       "      <td>min</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4140</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LMS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>minmax</td>\n",
       "      <td>GFAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>minmax</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>min</td>\n",
       "      <td>MUL</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>minmax</td>\n",
       "      <td>ADD</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>minmax</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>mean</td>\n",
       "      <td>MPL</td>\n",
       "      <td>59</td>\n",
       "      <td>0.040769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>zRecall</td>\n",
       "      <td>none</td>\n",
       "      <td>MUL</td>\n",
       "      <td>59</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5760 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             metric aggr_metric aggregation_strategy  group_id     value\n",
       "0     BoundedRecall        mean                  ADD         0  0.045000\n",
       "420   BoundedRecall         min             EPFuzzDA         0  0.010000\n",
       "4140           NDCG      minmax                  LMS         0  0.094384\n",
       "4080           NDCG      minmax                 GFAR         0  0.149834\n",
       "4020           NDCG      minmax             EPFuzzDA         0  0.120534\n",
       "...             ...         ...                  ...       ...       ...\n",
       "3959           NDCG         min                  MUL        59  0.000000\n",
       "4019           NDCG      minmax                  ADD        59  0.000000\n",
       "4079           NDCG      minmax             EPFuzzDA        59  0.000000\n",
       "3539           NDCG        mean                  MPL        59  0.040769\n",
       "5759        zRecall        none                  MUL        59  0.800000\n",
       "\n",
       "[5760 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(group_folds['value'].reset_index().sort_values(by='group_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>group_id</th>\n",
       "      <th>current_fold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>aggr_metric</th>\n",
       "      <th>aggregation_strategy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">BoundedRecall</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">mean</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.046897</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.044564</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>0.051674</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>0.041750</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>0.056576</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>0.046494</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">min</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.006985</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.006340</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>0.006329</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>0.005515</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>0.005941</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>0.006638</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">minmax</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.042177</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.042832</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>0.041152</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>0.033792</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>0.042454</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>0.040512</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">DCG</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">mean</th>\n",
       "      <th>ADD</th>\n",
       "      <td>1.811097</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>1.757440</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>1.708969</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>1.654917</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>1.943702</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>1.795502</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">min</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.280815</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.251230</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>0.240141</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>0.236478</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>0.281903</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>0.280874</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">minmax</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.044904</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.047528</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>0.041211</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>0.039898</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>0.060915</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>0.044792</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">DFH</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">mean</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.157501</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.160292</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>0.165883</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>0.148321</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>0.169513</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>0.157542</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">min</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.028561</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.028346</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>0.022370</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>0.026087</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>0.021984</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>0.027879</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">minmax</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.060482</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.059328</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   value  group_id  \\\n",
       "metric        aggr_metric aggregation_strategy                       \n",
       "BoundedRecall mean        ADD                   0.046897      29.5   \n",
       "                          EPFuzzDA              0.044564      29.5   \n",
       "                          GFAR                  0.051674      29.5   \n",
       "                          LMS                   0.041750      29.5   \n",
       "                          MPL                   0.056576      29.5   \n",
       "                          MUL                   0.046494      29.5   \n",
       "              min         ADD                   0.006985      29.5   \n",
       "                          EPFuzzDA              0.006340      29.5   \n",
       "                          GFAR                  0.006329      29.5   \n",
       "                          LMS                   0.005515      29.5   \n",
       "                          MPL                   0.005941      29.5   \n",
       "                          MUL                   0.006638      29.5   \n",
       "              minmax      ADD                   0.042177      29.5   \n",
       "                          EPFuzzDA              0.042832      29.5   \n",
       "                          GFAR                  0.041152      29.5   \n",
       "                          LMS                   0.033792      29.5   \n",
       "                          MPL                   0.042454      29.5   \n",
       "                          MUL                   0.040512      29.5   \n",
       "DCG           mean        ADD                   1.811097      29.5   \n",
       "                          EPFuzzDA              1.757440      29.5   \n",
       "                          GFAR                  1.708969      29.5   \n",
       "                          LMS                   1.654917      29.5   \n",
       "                          MPL                   1.943702      29.5   \n",
       "                          MUL                   1.795502      29.5   \n",
       "              min         ADD                   0.280815      29.5   \n",
       "                          EPFuzzDA              0.251230      29.5   \n",
       "                          GFAR                  0.240141      29.5   \n",
       "                          LMS                   0.236478      29.5   \n",
       "                          MPL                   0.281903      29.5   \n",
       "                          MUL                   0.280874      29.5   \n",
       "              minmax      ADD                   0.044904      29.5   \n",
       "                          EPFuzzDA              0.047528      29.5   \n",
       "                          GFAR                  0.041211      29.5   \n",
       "                          LMS                   0.039898      29.5   \n",
       "                          MPL                   0.060915      29.5   \n",
       "                          MUL                   0.044792      29.5   \n",
       "DFH           mean        ADD                   0.157501      29.5   \n",
       "                          EPFuzzDA              0.160292      29.5   \n",
       "                          GFAR                  0.165883      29.5   \n",
       "                          LMS                   0.148321      29.5   \n",
       "                          MPL                   0.169513      29.5   \n",
       "                          MUL                   0.157542      29.5   \n",
       "              min         ADD                   0.028561      29.5   \n",
       "                          EPFuzzDA              0.028346      29.5   \n",
       "                          GFAR                  0.022370      29.5   \n",
       "                          LMS                   0.026087      29.5   \n",
       "                          MPL                   0.021984      29.5   \n",
       "                          MUL                   0.027879      29.5   \n",
       "              minmax      ADD                   0.060482      29.5   \n",
       "                          EPFuzzDA              0.059328      29.5   \n",
       "\n",
       "                                                current_fold  \n",
       "metric        aggr_metric aggregation_strategy                \n",
       "BoundedRecall mean        ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "              min         ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "              minmax      ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "DCG           mean        ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "              min         ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "              minmax      ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "DFH           mean        ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "              min         ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "              minmax      ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.groupby(['metric', 'aggr_metric', 'aggregation_strategy']).mean().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
