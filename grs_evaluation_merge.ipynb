{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import settings.config as cfg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "preprocessed_dataset_folder = cfg.preprocessed_dataset_folder\n",
    "individual_rs_strategy = cfg.individual_rs_strategy\n",
    "aggregation_strategies = cfg.aggregation_strategies\n",
    "recommendations_number = cfg.recommendations_number\n",
    "individual_rs_validation_folds_k = cfg.individual_rs_validation_folds_k\n",
    "group_rs_evaluation_folds_k = cfg.group_rs_evaluation_folds_k\n",
    "evaluation_strategy = cfg.evaluation_strategy\n",
    "metrics = cfg.metrics\n",
    "\n",
    "print(cfg.feedback_polarity_debiasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4805, 5428]},\n",
       " 1: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5251, 146]},\n",
       " 2: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3916, 4539]},\n",
       " 3: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2059, 5558]},\n",
       " 4: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1789, 463]},\n",
       " 5: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3234, 4068]},\n",
       " 6: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5216, 4855]},\n",
       " 7: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [339, 5736]},\n",
       " 8: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [153, 4515]},\n",
       " 9: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3450, 2157]},\n",
       " 10: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [707, 2380]},\n",
       " 11: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [379, 3986]},\n",
       " 12: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3752, 3705]},\n",
       " 13: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [209, 1288]},\n",
       " 14: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3929, 751]},\n",
       " 15: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4751, 497]},\n",
       " 16: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3308, 197]},\n",
       " 17: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [417, 1226]},\n",
       " 18: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4699, 5990]},\n",
       " 19: {'group_size': 2,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2498, 3463]},\n",
       " 20: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3193, 4620, 3834, 4336]},\n",
       " 21: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2327, 2358, 671, 1532]},\n",
       " 22: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5896, 5350, 4113, 3112]},\n",
       " 23: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [602, 404, 1534, 3293]},\n",
       " 24: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3740, 3842, 5716, 3111]},\n",
       " 25: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1867, 4910, 2163, 4817]},\n",
       " 26: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1723, 2447, 1826, 1002]},\n",
       " 27: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2720, 5726, 3355, 5375]},\n",
       " 28: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4455, 1427, 4391, 5096]},\n",
       " 29: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2218, 4055, 4617, 2873]},\n",
       " 30: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1551, 2534, 5334, 4506]},\n",
       " 31: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [867, 3743, 729, 3771]},\n",
       " 32: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1969, 3791, 75, 1891]},\n",
       " 33: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [6036, 4306, 4495, 5157]},\n",
       " 34: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5470, 2348, 2466, 2433]},\n",
       " 35: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4787, 2909, 5884, 1140]},\n",
       " 36: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2307, 4005, 3306, 3542]},\n",
       " 37: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1514, 2163, 99, 1136]},\n",
       " 38: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5741, 5573, 589, 5770]},\n",
       " 39: {'group_size': 4,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5167, 790, 1518, 431]},\n",
       " 40: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3148, 784, 2597, 6014, 3195, 2424, 187, 4874]},\n",
       " 41: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2510, 5161, 1136, 4001, 5018, 165, 173, 4958]},\n",
       " 42: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2830, 3352, 3537, 2138, 3470, 401, 4360, 4101]},\n",
       " 43: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5320, 5423, 918, 4, 2708, 3836, 4318, 1632]},\n",
       " 44: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [491, 1357, 4708, 1947, 140, 2146, 5530, 446]},\n",
       " 45: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4482, 210, 5756, 1520, 3973, 5051, 2582, 497]},\n",
       " 46: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1866, 4876, 65, 4003, 2698, 3855, 2731, 629]},\n",
       " 47: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4727, 4445, 3875, 1577, 2681, 3843, 4407, 3700]},\n",
       " 48: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1657, 2128, 5424, 1089, 4613, 5892, 832, 3633]},\n",
       " 49: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3588, 3602, 5963, 409, 1820, 1932, 5462, 5819]},\n",
       " 50: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4269, 4569, 1562, 4714, 2971, 6003, 3487, 470]},\n",
       " 51: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2252, 3369, 5630, 5817, 1536, 1082, 5692, 2344]},\n",
       " 52: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [2491, 4959, 3670, 158, 6006, 749, 1473, 2567]},\n",
       " 53: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1917, 1000, 4182, 3256, 1531, 357, 5578, 4853]},\n",
       " 54: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4131, 2227, 5176, 691, 1240, 422, 238, 3158]},\n",
       " 55: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [3219, 3129, 3643, 3326, 964, 3246, 2025, 3114]},\n",
       " 56: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [5652, 640, 2384, 480, 3659, 1103, 5932, 2577]},\n",
       " 57: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [4182, 4312, 677, 5719, 546, 819, 2089, 1357]},\n",
       " 58: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1126, 3482, 2410, 5749, 698, 513, 837, 2050]},\n",
       " 59: {'group_size': 8,\n",
       "  'group_similarity': 'random',\n",
       "  'group_members': [1989, 1619, 1617, 319, 4190, 4578, 2623, 1879]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ratings_df = pd.read_csv(preprocessed_dataset_folder+\"/ratings.csv\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "group_composition = pickle.load(open(preprocessed_dataset_folder+\"/group_composition.pkl\", \"rb\"))\n",
    "display(group_composition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "\n",
    "# Train individual recommender system and predict ratings\n",
    "def train_individual_rs_and_get_predictions(training_df, test_df):\n",
    "    if cfg.individual_rs_strategy == \"LENSKIT_CF_USER\":\n",
    "        print(cfg.individual_rs_strategy)\n",
    "        return train_lenskit_cf_user_rs_and_get_predictions(training_df, test_df)\n",
    "    if cfg.individual_rs_strategy == \"LENSKIT_CF_ITEM\":\n",
    "        print(cfg.individual_rs_strategy)\n",
    "        return train_lenskit_cf_item_rs_and_get_predictions(training_df, test_df)    \n",
    "    return None\n",
    "    \n",
    "from lenskit.algorithms import Recommender\n",
    "from lenskit.algorithms.user_knn import UserUser\n",
    "from lenskit.algorithms.item_knn import ItemItem\n",
    "\n",
    "# Train lenskit CF user-user individual recommender system and predict ratings\n",
    "def train_lenskit_cf_user_rs_and_get_predictions(training_df, test_df):\n",
    "    if cfg.individual_rs_validation_folds_k <=0:\n",
    "        print(\"training\")\n",
    "        # Basic implementation: no hyperparameters validation\n",
    "        user_user = UserUser(15, min_nbrs=3)  # Minimum (3) and maximum (15) number of neighbors to consider\n",
    "        recsys = Recommender.adapt(user_user)\n",
    "        recsys.fit(training_df)\n",
    "        \n",
    "        print(\"evaluating predictions\")\n",
    "        # Evaluating predictions \n",
    "        test_df['predicted_rating'] = recsys.predict(test_df)\n",
    "        print(\"Done!\")\n",
    "        return test_df\n",
    "    return None    \n",
    "\n",
    "# Train lenskit CF item-item individual recommender system and predict ratings\n",
    "def train_lenskit_cf_item_rs_and_get_predictions(training_df, test_df):\n",
    "    if cfg.individual_rs_validation_folds_k <=0:\n",
    "        print(\"training\")\n",
    "        # Basic implementation: no hyperparameters validation\n",
    "        item_item = ItemItem(15, min_nbrs=3)  # Minimum (3) and maximum (15) number of neighbors to consider\n",
    "        recsys = Recommender.adapt(item_item)\n",
    "        recsys.fit(training_df)\n",
    "        \n",
    "        print(\"evaluating predictions\")\n",
    "        # Evaluating predictions \n",
    "        test_df['predicted_rating'] = recsys.predict(test_df)\n",
    "        print(\"Done!\")\n",
    "        return test_df\n",
    "    return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Aggregation strategies\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class AggregationStrategy(ABC):\n",
    "    \n",
    "    @staticmethod\n",
    "    def getAggregator(strategy):            \n",
    "        if strategy==\"ADD\":\n",
    "            return AdditiveAggregator()\n",
    "        elif strategy==\"LMS\":\n",
    "            return LeastMiseryAggregator()\n",
    "        elif strategy==\"BASE\":\n",
    "            return BaselinesAggregator()\n",
    "        elif strategy==\"GFAR\":\n",
    "            return GFARAggregator()     \n",
    "        elif strategy==\"EPFuzzDA\":\n",
    "            return EPFuzzDAAggregator()        \n",
    "        return None\n",
    "    \n",
    "    @abstractmethod\n",
    "    def generate_group_recommendations_for_group(self, group_ratings, recommendations_number):\n",
    "        pass\n",
    "    \n",
    "\n",
    "class AdditiveAggregator(AggregationStrategy):    \n",
    "    def generate_group_recommendations_for_group(self, group_ratings, recommendations_number):\n",
    "        aggregated_df = group_ratings.groupby('item').sum()\n",
    "        aggregated_df = aggregated_df.sort_values(by=\"predicted_rating\", ascending=False).reset_index()[['item', 'predicted_rating']]\n",
    "        recommendation_list = list(aggregated_df.head(recommendations_number)['item'])\n",
    "        return {\"ADD\" : recommendation_list}\n",
    "    \n",
    "class LeastMiseryAggregator(AggregationStrategy):    \n",
    "    def generate_group_recommendations_for_group(self, group_ratings, recommendations_number):\n",
    "        # aggregate using least misery strategy\n",
    "        aggregated_df = group_ratings.groupby('item').min()\n",
    "        aggregated_df = aggregated_df.sort_values(by=\"predicted_rating\", ascending=False).reset_index()[['item', 'predicted_rating']]\n",
    "        recommendation_list = list(aggregated_df.head(recommendations_number)['item'])\n",
    "        return {\"LMS\" : recommendation_list}\n",
    "\n",
    "class BaselinesAggregator(AggregationStrategy):    \n",
    "    def generate_group_recommendations_for_group(self, group_ratings, recommendations_number):\n",
    "        # aggregate using least misery strategy\n",
    "        aggregated_df = group_ratings.groupby('item').agg({\"predicted_rating\": [np.sum, np.prod,np.min,np.max]})\n",
    "        aggregated_df = aggregated_df[\"predicted_rating\"].reset_index()\n",
    "        # additive\n",
    "        \n",
    "        add_df = aggregated_df.sort_values(by=\"sum\", ascending=False).reset_index()[['item', 'sum']]\n",
    "        add_recommendation_list = list(add_df.head(recommendations_number)['item'])\n",
    "        # multiplicative\n",
    "        mul_df = aggregated_df.sort_values(by=\"prod\", ascending=False).reset_index()[['item', 'prod']]\n",
    "        mul_recommendation_list = list(mul_df.head(recommendations_number)['item'])\n",
    "        # least misery\n",
    "        lms_df = aggregated_df.sort_values(by=\"amin\", ascending=False).reset_index()[['item', 'amin']]\n",
    "        lms_recommendation_list = list(lms_df.head(recommendations_number)['item'])\n",
    "        # most pleasure\n",
    "        mpl_df = aggregated_df.sort_values(by=\"amax\", ascending=False).reset_index()[['item', 'amax']]\n",
    "        mpl_recommendation_list = list(mpl_df.head(recommendations_number)['item'])\n",
    "        return {\n",
    "            \"ADD\" : add_recommendation_list, \n",
    "            \"MUL\" : mul_recommendation_list, \n",
    "            \"LMS\" : lms_recommendation_list, \n",
    "            \"MPL\" : mpl_recommendation_list\n",
    "        }\n",
    "    \n",
    "class GFARAggregator(AggregationStrategy):\n",
    "    #implements GFAR aggregation algorithm. For more details visit https://dl.acm.org/doi/10.1145/3383313.3412232\n",
    "\n",
    "    #create an index-wise top-k selection w.r.t. list of scores\n",
    "    def select_top_n_idx(self, score_df, top_n, top='max', sort=True):\n",
    "        if top != 'max' and top != 'min':\n",
    "            raise ValueError('top must be either Max or Min')\n",
    "        if top == 'max':\n",
    "            score_df.loc[score_df.index,\"predicted_rating_rev\"] = -score_df[\"predicted_rating\"]\n",
    "\n",
    "        select_top_n = top_n\n",
    "        top_n_ind = np.argpartition(score_df.predicted_rating_rev, select_top_n)[:select_top_n]        \n",
    "        top_n_df = score_df.iloc[top_n_ind]\n",
    "\n",
    "        if sort:\n",
    "            return top_n_df.sort_values(\"predicted_rating_rev\")\n",
    "\n",
    "        return top_n_df\n",
    "\n",
    "    # borda count that is limited only to top-max_rel_items, if you are not in the top-max_rel_items, you get 0\n",
    "    def get_borda_rel(self, candidate_group_items_df, max_rel_items):  \n",
    "        from scipy.stats import rankdata\n",
    "        top_records = self.select_top_n_idx(candidate_group_items_df, max_rel_items, top='max', sort=False)        \n",
    "        \n",
    "        rel_borda = rankdata(top_records[\"predicted_rating_rev\"].values, method='max')\n",
    "        #candidate_group_items_df.loc[top_records.index,\"borda_score\"] = rel_borda\n",
    "        return (top_records.index, rel_borda)\n",
    "\n",
    "    # runs GFAR algorithm for one group\n",
    "    def gfar_algorithm(self, group_ratings, top_n: int, relevant_max_items: int, n_candidates: int):      \n",
    "        \n",
    "        group_members = group_ratings.user.unique()\n",
    "        group_size = len(group_members)\n",
    "        \n",
    "        localDF = group_ratings.copy()\n",
    "        localDF[\"predicted_rating_rev\"] = 0.0\n",
    "        localDF[\"borda_score\"] = 0.0\n",
    "        localDF[\"p_relevant\"] = 0.0\n",
    "        localDF[\"prob_selected_not_relevant\"] = 1.0\n",
    "        localDF[\"marginal_gain\"] = 0.0\n",
    "        \n",
    "        #filter-out completely irrelevant items to decrease computational complexity        \n",
    "        #top_candidates_ids_per_member = []\n",
    "        #for uid in  group_members:\n",
    "        #    per_user_ratings = group_ratings.loc[group_ratings.user == uid]\n",
    "        #    top_candidates_ids_per_member.append(select_top_n_idx(per_user_ratings, n_candidates, sort=False)[\"item\"].values)\n",
    "        \n",
    "\n",
    "        #top_candidates_idx = np.unique(np.array(top_candidates_ids_per_member))\n",
    "        \n",
    "        # get the candidate group items for each member\n",
    "        #candidate_group_ratings = group_ratings.loc[group_ratings[\"items\"].isin(top_candidates_idx)]\n",
    "        \n",
    "        \n",
    "        for uid in group_members:\n",
    "            per_user_candidates = localDF.loc[localDF.user == uid]\n",
    "            borda_index, borda_score = self.get_borda_rel(per_user_candidates, relevant_max_items)\n",
    "            localDF.loc[borda_index,\"borda_score\"] = borda_score\n",
    "        \n",
    "            total_relevance_for_users = localDF.loc[borda_index,\"borda_score\"].sum()\n",
    "            localDF.loc[borda_index,\"p_relevant\"] = localDF.loc[borda_index,\"borda_score\"] / total_relevance_for_users\n",
    "            \n",
    "\n",
    "        selected_items = []\n",
    "\n",
    "        # top-n times select one item to the final list\n",
    "        for i in range(top_n):\n",
    "            localDF.loc[:,\"marginal_gain\"] = localDF.p_relevant * localDF.prob_selected_not_relevant\n",
    "            item_marginal_gain = localDF.groupby(\"item\")[\"marginal_gain\"].sum()\n",
    "            # select the item with the highest marginal gain\n",
    "            item_pos = item_marginal_gain.argmax()\n",
    "            item_id = item_marginal_gain.index[item_pos]\n",
    "            selected_items.append(item_id)\n",
    "\n",
    "            # update the probability of selected items not being relevant\n",
    "            for uid in group_members:\n",
    "                winner_row = localDF.loc[((localDF[\"item\"]== item_id)&(localDF[\"user\"]== uid))]\n",
    "                \n",
    "                #only update if any record for user-item was found\n",
    "                if winner_row.shape[0]>0:\n",
    "                    p_rel = winner_row[\"p_relevant\"].values[0]\n",
    "                    p_not_selected = winner_row[\"prob_selected_not_relevant\"].values[0] * (1 - p_rel)\n",
    "                \n",
    "                    localDF.loc[localDF[\"user\"]== uid,\"prob_selected_not_relevant\"] = p_not_selected\n",
    "            \n",
    "            #remove winning item from the list of candidates\n",
    "            localDF.drop(localDF.loc[localDF[\"item\"] == item_id].index, inplace=True)\n",
    "        return selected_items\n",
    "    \n",
    "    def generate_group_recommendations_for_group(self, group_ratings, recommendations_number):\n",
    "        selected_items = self.gfar_algorithm( group_ratings, recommendations_number, 20, 500)        \n",
    "        return {\"GFAR\" : selected_items}\n",
    "    \n",
    "    \n",
    "class EPFuzzDAAggregator(AggregationStrategy):\n",
    "    #implements EP-FuzzDA aggregation algorithm. For more details visit https://dl.acm.org/doi/10.1145/3450614.3461679\n",
    "\n",
    "    def ep_fuzzdhondt_algorithm(self, group_ratings, top_n, member_weights=None):\n",
    "        group_members = group_ratings.user.unique()\n",
    "        all_items = group_ratings[\"item\"].unique()\n",
    "        group_size = len(group_members)\n",
    "\n",
    "        if not member_weights:\n",
    "            member_weights = [1./group_size] * group_size\n",
    "        member_weights = pd.DataFrame(pd.Series(member_weights, index=group_members))\n",
    "        \n",
    "        localDF = group_ratings.copy()\n",
    "      \n",
    "        candidate_utility = pd.pivot_table(localDF, values=\"predicted_rating\", index=\"item\", columns=\"user\", fill_value=0.0)\n",
    "        candidate_sum_utility = pd.DataFrame(candidate_utility.sum(axis=\"columns\"))\n",
    "        \n",
    "        total_user_utility_awarded = pd.Series(np.zeros(group_size), index=group_members)\n",
    "        total_utility_awarded = 0.\n",
    "\n",
    "        selected_items = []\n",
    "        # top-n times select one item to the final list\n",
    "        for i in range(top_n):\n",
    "            # print()\n",
    "            # print('Selecting item {}'.format(i))\n",
    "            # print('Total utility awarded: ', total_utility_awarded)\n",
    "            # print('Total user utility awarded: ', total_user_utility_awarded)\n",
    "\n",
    "            prospected_total_utility = candidate_sum_utility + total_utility_awarded #pd.DataFrame items x 1\n",
    "            \n",
    "            \n",
    "            #print(prospected_total_utility.shape, member_weights.T.shape)\n",
    "            \n",
    "            allowed_utility_for_users = pd.DataFrame(np.dot(prospected_total_utility.values, member_weights.T.values), columns=member_weights.T.columns, index=prospected_total_utility.index)\n",
    "                                                          \n",
    "            #print(allowed_utility_for_users.shape)\n",
    "            \n",
    "            #cap the item's utility by the already assigned utility per user\n",
    "            unfulfilled_utility_for_users = allowed_utility_for_users.subtract(total_user_utility_awarded, axis=\"columns\")\n",
    "            unfulfilled_utility_for_users[unfulfilled_utility_for_users < 0] = 0 \n",
    "                                               \n",
    "            candidate_user_relevance = pd.concat([unfulfilled_utility_for_users,candidate_utility]).min(level=0)                                               \n",
    "            candidate_relevance = candidate_user_relevance.sum(axis=\"columns\")\n",
    "             \n",
    "            #remove already selected items\n",
    "            candidate_relevance = candidate_relevance.loc[~candidate_relevance.index.isin(selected_items)]\n",
    "            item_pos = candidate_relevance.argmax()\n",
    "            item_id = candidate_relevance.index[item_pos]  \n",
    "            \n",
    "            #print(item_pos,item_id,candidate_relevance[item_id])\n",
    "            \n",
    "            #print(candidate_relevance.index.difference(candidate_utility.index))\n",
    "            #print(item_id in candidate_relevance.index, item_id in candidate_utility.index)\n",
    "            selected_items.append(item_id)\n",
    "            \n",
    "            winner_row = candidate_utility.loc[item_id,:]\n",
    "            #print(winner_row)\n",
    "            #print(winner_row.shape)\n",
    "            #print(item_id,item_pos,candidate_relevance.max())\n",
    "            #print(selected_items)\n",
    "            #print(total_user_utility_awarded)\n",
    "            #print(winner_row.iloc[0,:])\n",
    "            \n",
    "            total_user_utility_awarded.loc[:] = total_user_utility_awarded.loc[:] + winner_row\n",
    "            \n",
    "            total_utility_awarded += winner_row.values.sum()\n",
    "            #print(total_user_utility_awarded)\n",
    "            #print(total_utility_awarded)\n",
    "            \n",
    "        \n",
    "        return selected_items\n",
    "    \n",
    "    def generate_group_recommendations_for_group(self, group_ratings, recommendations_number):\n",
    "        selected_items = self.ep_fuzzdhondt_algorithm( group_ratings, recommendations_number)        \n",
    "        return {\"EPFuzzDA\" : selected_items}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating recommendations for all the aggregation strategies\n",
    "\n",
    "# def generate_group_recommendations_forall_aggr_strat(test_df, group_composition, recommendations_number):\n",
    "#     group_recommendations = dict()\n",
    "#     for aggregation_strategy in cfg.aggregation_strategies:\n",
    "#         print(datetime.now(), aggregation_strategy)\n",
    "#         agg = AggregationStrategy.getAggregator(aggregation_strategy)\n",
    "#         group_recommendations[aggregation_strategy] = agg.generate_group_recommendations_forall_groups(test_df, group_composition, recommendations_number)\n",
    "        \n",
    "#     return group_recommendations\n",
    "\n",
    "def generate_group_recommendations_forall_groups(test_df, group_composition, recommendations_number):\n",
    "    group_recommendations = dict()\n",
    "    for group_id in group_composition:\n",
    "        \n",
    "#         print(datetime.now(), group_id)\n",
    "        \n",
    "        # extract group info\n",
    "        group = group_composition[group_id]\n",
    "        group_size = group['group_size']\n",
    "        group_similarity = group['group_similarity']\n",
    "        group_members = group['group_members']\n",
    "            \n",
    "        # filter ratings for the group members\n",
    "        group_ratings = test_df.loc[test_df['user'].isin(group_members)]\n",
    "        \n",
    "        group_rec = dict()\n",
    "        for aggregation_strategy in cfg.aggregation_strategies:\n",
    "#             print(datetime.now(), aggregation_strategy)\n",
    "            agg = AggregationStrategy.getAggregator(aggregation_strategy)\n",
    "            group_rec = {**group_rec, **agg.generate_group_recommendations_for_group(group_ratings, recommendations_number)}\n",
    "        \n",
    "        \n",
    "        group_recommendations[group_id] = group_rec\n",
    "        \n",
    "    return group_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing for inverse propensity weighting, \n",
    "#for more details visit https://dl.acm.org/doi/abs/10.1145/3240323.3240355\n",
    "def calculate_inverse_propensity_score(ratings_df, train_df, propensity_gama):\n",
    "    items = ratings_df[\"item\"].unique()\n",
    "    \n",
    "    #failsafe if some of the items never appeared in train data\n",
    "    propensity_per_item = pd.DataFrame(1.0, index=items, columns=[\"propensity_score\"])\n",
    "    \n",
    "    n_i_star_vector = train_df.groupby(\"item\")[\"rating\"].count()\n",
    "    P_ui_vector = n_i_star_vector**((propensity_gama+1)/2)\n",
    "    propensity_per_item.loc[P_ui_vector.index,\"propensity_score\"] = P_ui_vector\n",
    "\n",
    "        \n",
    "    return propensity_per_item   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing for inverse propensity weighting\n",
    "#Calculating  per-user fixed term of 1/\\sum_{i \\in R_u}(1/P_{u,i}), \n",
    "#    where R_u is a list of items known by user u and P_{u,i} is their propensity score\n",
    "def calculate_inverse_propensity_score_user_normalization(propensity_per_item, test_df):\n",
    "    inverse_propensity = 1/propensity_per_item\n",
    "    \n",
    "    local_df = test_df.copy()\n",
    "    local_df = local_df.join(inverse_propensity, on=\"item\")\n",
    "    \n",
    "    per_user_normalization_term = 1/local_df.groupby(\"user\")[\"propensity_score\"].sum()\n",
    "        \n",
    "    return per_user_normalization_term "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Evaluation Metrics strategies\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class MetricEvaluator(ABC):\n",
    "    \n",
    "    @staticmethod\n",
    "    def getMetricEvaluator(metric):            \n",
    "        if metric==\"NDCG\":\n",
    "            return NDCGEvaluator()\n",
    "        elif metric==\"DCG\":\n",
    "            return DCGEvaluator()\n",
    "        elif metric==\"BINARY\":\n",
    "            return BinaryEvaluator()        \n",
    "        elif metric==\"BASE\":\n",
    "            return BaselinesEvaluators()\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    @abstractmethod\n",
    "    def evaluateGroupRecommendation(self, group_ground_truth, group_recommendation, group_members):\n",
    "        pass\n",
    "    \n",
    "\n",
    "class NDCGEvaluator(MetricEvaluator):\n",
    "    \n",
    "    def evaluateUserNDCG(self, user_ground_truth, group_recommendation, user_norm):\n",
    "        # note that both dcg and idcg should be element-wise normalized via per_user_propensity_normalization_term\n",
    "        # therefore, it can be excluded from calculations        \n",
    "        dcg = 0\n",
    "#         display(user_ground_truth)\n",
    "#         display(group_recommendation)\n",
    "        for k, item in enumerate(group_recommendation):\n",
    "            dcg = dcg + ((user_ground_truth.loc[item,\"final_rating\"] if item in user_ground_truth.index else 0) / np.log2(k+2))\n",
    "        \n",
    "        idcg = 0\n",
    "        # what if intersection is empty?\n",
    "        user_ground_truth.sort_values(\"final_rating\", inplace=True, ascending=False)\n",
    "        #print(user_ground_truth)\n",
    "        #print(len(user_ground_truth),len(group_recommendation),min(len(user_ground_truth),len(group_recommendation)))\n",
    "        for k in range(min(len(user_ground_truth),len(group_recommendation))):\n",
    "            idcg = idcg + (user_ground_truth.iloc[k][\"final_rating\"] / np.log2(k+2))\n",
    "        if idcg > 0:    \n",
    "            ndcg = dcg / idcg\n",
    "        else:\n",
    "            ndcg = 0\n",
    "        \n",
    "        return ndcg, user_norm*dcg\n",
    "        \n",
    "    def evaluateGroupRecommendation(self, group_ground_truth, group_recommendation, group_members):\n",
    "        ndcg_list = list()\n",
    "        dcg_list = list()\n",
    "        for user in group_members:\n",
    "\n",
    "            user_ground_truth = ground_truth.loc[ground_truth['user']==user]        \n",
    "            user_ground_truth.set_index(\"item\", inplace=True)\n",
    "            \n",
    "            # basic polarity debiasing (max(0, rating + c))\n",
    "            if cfg.feedback_polarity_debiasing != 0.0:\n",
    "                user_ground_truth[\"final_rating\"] = user_ground_truth.loc[:,\"rating\"] + cfg.feedback_polarity_debiasing\n",
    "                user_ground_truth.loc[user_ground_truth.final_rating < 0,\"final_rating\"] = 0            \n",
    "            # feedback binarization\n",
    "            elif cfg.binarize_feedback == True:\n",
    "                user_ground_truth[\"final_rating\"] = 0\n",
    "                user_ground_truth.loc[user_ground_truth.rating >= cfg.binarize_feedback_positive_threshold,\"final_rating\"] = 1\n",
    "            # no modifications to feedback\n",
    "            else:\n",
    "                user_ground_truth[\"final_rating\"] = user_ground_truth[\"rating\"]            \n",
    "            \n",
    "            #inverse propensity weighting of items\n",
    "            user_ground_truth.loc[:,\"final_rating\"] = user_ground_truth.loc[:,\"final_rating\"] / propensity_per_item[\"propensity_score\"]\n",
    "            #inverse propensity per-user normalization\n",
    "            user_norm = 1.0\n",
    "            if per_user_propensity_normalization_term is not None:\n",
    "                user_norm = per_user_propensity_normalization_term[user]            \n",
    "            \n",
    "            ndcg_user, dcg_user = self.evaluateUserNDCG(user_ground_truth, group_recommendation, user_norm)\n",
    "            ndcg_list.append(ndcg_user)\n",
    "            dcg_list.append(dcg_user)\n",
    "            \n",
    "            #failsafe for all negative results\n",
    "            if np.amax(ndcg_list) > 0:\n",
    "                ndcg_min_max = np.amin(ndcg_list)/np.amax(ndcg_list)\n",
    "                dcg_min_max = np.amin(dcg_list)/np.amax(dcg_list)\n",
    "            else:\n",
    "                ndcg_min_max = 0.0\n",
    "                dcg_min_max = 0.0\n",
    "        return [\n",
    "            {\n",
    "                \"metric\" : \"NDCG\",\n",
    "                \"aggr_metric\" : \"mean\",\n",
    "                \"value\" : np.mean(ndcg_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"NDCG\",\n",
    "                \"aggr_metric\" : \"min\",\n",
    "                \"value\" : np.amin(ndcg_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"NDCG\",\n",
    "                \"aggr_metric\" : \"minmax\",\n",
    "                \"value\" : ndcg_min_max\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"DCG\",\n",
    "                \"aggr_metric\" : \"mean\",\n",
    "                \"value\" : np.mean(dcg_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"DCG\",\n",
    "                \"aggr_metric\" : \"min\",\n",
    "                \"value\" : np.amin(dcg_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"DCG\",\n",
    "                \"aggr_metric\" : \"minmax\",\n",
    "                \"value\" : dcg_min_max\n",
    "            }            \n",
    "        ]\n",
    "\n",
    "    \n",
    "class BinaryEvaluator(MetricEvaluator):\n",
    "    \n",
    "    def evaluateUserBinary(self, user_ground_truth, group_recommendation, user_norm):     \n",
    "        correct_recs_list = user_ground_truth.loc[(user_ground_truth.index.isin(group_recommendation))&(user_ground_truth.final_rating > 0)]\n",
    "        correct_recs = correct_recs_list.shape[0]\n",
    "        all_correct_per_user = user_ground_truth.loc[user_ground_truth.final_rating > 0].shape[0]\n",
    "        if all_correct_per_user == 0:\n",
    "            return (0.0,0.0,0.0)\n",
    "        recall = user_norm * correct_recs / all_correct_per_user\n",
    "        \n",
    "        #bounded recall, denominator is min(# of relevant items, length of the list)\n",
    "        all_correct_per_user_caped = min([all_correct_per_user,len(group_recommendation)])\n",
    "        bounded_recall = user_norm * correct_recs / all_correct_per_user_caped\n",
    "        \n",
    "        #discounted first hit\n",
    "        if correct_recs == 0:\n",
    "            dfh = 0.0\n",
    "        else:\n",
    "            for k,item in enumerate(group_recommendation):\n",
    "                if item in correct_recs_list.index:\n",
    "                    first_hit_rank = k\n",
    "                    break\n",
    "            dfh = user_norm * 1 / np.log2(first_hit_rank+2)   \n",
    "                                    \n",
    "        \n",
    "        return (recall, bounded_recall, dfh)\n",
    "        \n",
    "        \n",
    "    def evaluateGroupRecommendation(self, group_ground_truth, group_recommendation, group_members):\n",
    "        #Irrespective of the cfg.binarize_feedback setting, we need binary feedback for this set of metrics\n",
    "        #Use binary_positive_threshold, but do not use polarity_debiasing (kind of does the same thing)\n",
    "        recall_list = list()\n",
    "        bounded_recall_list = list()\n",
    "        dfh_list = list()\n",
    "        zero_recall = 0\n",
    "        for user in group_members:\n",
    "            user_ground_truth = ground_truth.loc[ground_truth['user']==user]          \n",
    "            user_ground_truth.set_index(\"item\", inplace=True)            \n",
    "            \n",
    "            #feedback binarization\n",
    "            user_ground_truth[\"final_rating\"] = 0\n",
    "            user_ground_truth.loc[user_ground_truth.rating >= cfg.binarize_feedback_positive_threshold,\"final_rating\"] = 1\n",
    "                \n",
    "            #self-normalized inverse propensity debiasing\n",
    "            user_ground_truth.loc[:,\"final_rating\"] = user_ground_truth.loc[:,\"final_rating\"] / propensity_per_item[\"propensity_score\"]\n",
    "            user_norm = 1.0\n",
    "            if per_user_propensity_normalization_term is not None:\n",
    "                user_norm = per_user_propensity_normalization_term[user]\n",
    "            \n",
    "            recall_user, bounded_recall_user, dfh_user = self.evaluateUserBinary(user_ground_truth, group_recommendation, user_norm)\n",
    "            if recall_user == 0:                \n",
    "                zero_recall +=  1\n",
    "\n",
    "            recall_list.append(recall_user)\n",
    "            bounded_recall_list.append(bounded_recall_user)\n",
    "            dfh_list.append(dfh_user)\n",
    "            \n",
    "        #failsafe for all negative results\n",
    "        if np.amax(recall_list) > 0:\n",
    "            rec_min_max = np.amin(recall_list)/np.amax(recall_list)\n",
    "            bound_min_max = np.amin(bounded_recall_list)/np.amax(bounded_recall_list)\n",
    "            dfh_min_max = np.amin(dfh_list)/np.amax(dfh_list)\n",
    "        else:\n",
    "            rec_min_max = 0.0\n",
    "            bound_min_max = 0.0\n",
    "            dfh_min_max = 0.0\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                \"metric\" : \"Recall\",\n",
    "                \"aggr_metric\" : \"mean\",\n",
    "                \"value\" : np.mean(recall_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"Recall\",\n",
    "                \"aggr_metric\" : \"min\",\n",
    "                \"value\" : np.amin(recall_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"Recall\",\n",
    "                \"aggr_metric\" : \"minmax\",\n",
    "                \"value\" : rec_min_max\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"BoundedRecall\",\n",
    "                \"aggr_metric\" : \"mean\",\n",
    "                \"value\" : np.mean(bounded_recall_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"BoundedRecall\",\n",
    "                \"aggr_metric\" : \"min\",\n",
    "                \"value\" : np.amin(bounded_recall_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"BoundedRecall\",\n",
    "                \"aggr_metric\" : \"minmax\",\n",
    "                \"value\" : bound_min_max\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"DFH\",\n",
    "                \"aggr_metric\" : \"mean\",\n",
    "                \"value\" : np.mean(dfh_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"DFH\",\n",
    "                \"aggr_metric\" : \"min\",\n",
    "                \"value\" : np.amin(dfh_list)\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"DFH\",\n",
    "                \"aggr_metric\" : \"minmax\",\n",
    "                \"value\" : dfh_min_max\n",
    "            },\n",
    "            {\n",
    "                \"metric\" : \"zRecall\",\n",
    "                \"aggr_metric\" : \"none\",\n",
    "                \"value\" : zero_recall / len(group_members)\n",
    "            }\n",
    "        ]            \n",
    "    \n",
    "\n",
    "\n",
    "class BaselinesEvaluators(MetricEvaluator):\n",
    "    def evaluateGroupRecommendation(self, group_ground_truth, group_recommendation, group_members):\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_group_recommendations_forall_groups(ground_truth, group_recommendations, group_composition, current_fold):\n",
    "#     group_evaluations = dict()\n",
    "    group_evaluations = list()\n",
    "    for group_id in group_composition:\n",
    "        \n",
    "        #print(datetime.now(), group_id)\n",
    "        \n",
    "        # extract group info\n",
    "        group = group_composition[group_id]\n",
    "        group_size = group['group_size']\n",
    "        group_similarity = group['group_similarity']\n",
    "        group_members = group['group_members']\n",
    "        group_rec = group_recommendations[group_id]\n",
    "            \n",
    "        # filter ratings in ground_truth for the group members\n",
    "        group_ground_truth = ground_truth.loc[ground_truth['user'].isin(group_members)]\n",
    "        \n",
    "\n",
    "        for aggregation_strategy in group_rec:\n",
    "            agg_group_rec = group_rec[aggregation_strategy]\n",
    "            agg_group_rec_eval = list()\n",
    "            for metric in cfg.metrics:\n",
    "    #             print(datetime.now(), aggregation_strategy)\n",
    "                metric_evaluator = MetricEvaluator.getMetricEvaluator(metric)\n",
    "#                 agg_group_rec_eval = {**agg_group_rec_eval, **metric_evaluator.evaluateGroupRecommendation(group_ground_truth, agg_group_rec, group_members)}\n",
    "                agg_group_rec_eval = agg_group_rec_eval + metric_evaluator.evaluateGroupRecommendation(group_ground_truth, agg_group_rec, group_members)\n",
    "    \n",
    "            # Adding aggregation strategy info\n",
    "            for row in agg_group_rec_eval:\n",
    "                row['aggregation_strategy'] = aggregation_strategy\n",
    "                row['group_id'] = group_id\n",
    "                row['current_fold'] = current_fold\n",
    "#             group_rec_eval[aggregation_strategy] = agg_group_rec_eval\n",
    "        \n",
    "            #print(agg_group_rec_eval)\n",
    "            group_evaluations = group_evaluations + agg_group_rec_eval\n",
    "        # Adding group_id info\n",
    "#         group_evaluations[group_id] = group_rec_eval\n",
    "        \n",
    "    return group_evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-14 16:47:00.037424 Creating folds\n",
      "2022-09-14 16:47:00.038420 Folds created!\n",
      ">>> Start processing fold: Train 753780 Test: 188445\n",
      "2022-09-14 16:47:11.763517 Train individual RS and get predictions\n",
      "LENSKIT_CF_ITEM\n",
      "training\n",
      "evaluating predictions\n",
      "Done!\n",
      ">>> Start processing fold: Train 753780 Test: 188445\n",
      "2022-09-14 16:48:54.219652 Train individual RS and get predictions\n",
      "LENSKIT_CF_ITEM\n",
      "training\n",
      "evaluating predictions\n",
      "Done!\n",
      ">>> Start processing fold: Train 753780 Test: 188445\n",
      "2022-09-14 16:50:33.822935 Train individual RS and get predictions\n",
      "LENSKIT_CF_ITEM\n",
      "training\n",
      "evaluating predictions\n",
      "Done!\n",
      ">>> Start processing fold: Train 753780 Test: 188445\n",
      "2022-09-14 16:52:14.798907 Train individual RS and get predictions\n",
      "LENSKIT_CF_ITEM\n",
      "training\n",
      "evaluating predictions\n",
      "Done!\n",
      ">>> Start processing fold: Train 753780 Test: 188445\n",
      "2022-09-14 16:53:54.142324 Train individual RS and get predictions\n",
      "LENSKIT_CF_ITEM\n",
      "training\n",
      "evaluating predictions\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# General pipeline\n",
    "\n",
    "# creating train-test folds\n",
    "# split stratified on the users \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import itertools\n",
    "\n",
    "print(datetime.now(), \"Creating folds\")\n",
    "# skf = StratifiedKFold(n_splits=group_rs_evaluation_folds_k, random_state=None, shuffle=True)\n",
    "skf = StratifiedKFold(n_splits=group_rs_evaluation_folds_k, random_state=42, shuffle=True)\n",
    "\n",
    "print(datetime.now(), \"Folds created!\")\n",
    "current_fold = 0\n",
    "for train_index, test_index in skf.split(ratings_df, ratings_df['user']):\n",
    "    print(\">>> Start processing fold: Train\", len(train_index), \"Test:\", len(test_index))\n",
    "    \n",
    "    # split train and test df\n",
    "    train_df = ratings_df.iloc[train_index]\n",
    "    test_df = ratings_df.iloc[test_index]\n",
    "    \n",
    "    # getting user-items pairs in the training set\n",
    "    train_set_pairs = set(list(zip(train_df['user'].values,train_df['item'].values)))\n",
    "    \n",
    "    # create test_complete_df with all the possible user-items pairs in the test_df\n",
    "    user_set = set(test_df['user'].values)\n",
    "    item_set = set(test_df['item'].values)\n",
    "    all_ui_values = list(itertools.product(user_set, item_set))\n",
    "    test_pred_df = pd.DataFrame(all_ui_values, columns=['user', 'item'])\n",
    "    \n",
    "#     print(datetime.now(), \"Extended test df\")\n",
    "#     display(test_pred_df)\n",
    "    \n",
    "    print(datetime.now(), \"Train individual RS and get predictions\")\n",
    "    # train individual rs and get predictions\n",
    "    test_pred_df = train_individual_rs_and_get_predictions(train_df, test_pred_df)\n",
    "    \n",
    "    #correction for train set records (assuming repeated recommendations provide no value, therefore predicted_rating=0)\n",
    "    train_set_pairs = train_set_pairs.intersection(set(all_ui_values))\n",
    "    test_pred_df.set_index([\"user\",\"item\"], inplace=True)\n",
    "    test_pred_df.loc[train_set_pairs,\"predicted_rating\"] = 0.0\n",
    "    test_pred_df.reset_index(inplace=True)\n",
    "    \n",
    "    path_to_fold = preprocessed_dataset_folder+\"/fold_\"+str(current_fold)\n",
    "    \n",
    "    if not os.path.exists(path_to_fold):\n",
    "        os.mkdir(path_to_fold)\n",
    "        \n",
    "    pickle.dump(train_df, open(path_to_fold+\"/train_df.pkl\", \"wb\"))\n",
    "    pickle.dump(test_df, open(path_to_fold+\"/test_df.pkl\", \"wb\"))\n",
    "    pickle.dump(test_pred_df, open(path_to_fold+\"/test_pred_df.pkl\", \"wb\"))\n",
    "    \n",
    "    current_fold = current_fold + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-14 17:07:12.126510 fold_0: Generate GRS for all the aggregation strategies and all the groups\n",
      "2022-09-14 17:07:27.790974 fold_1: Generate GRS for all the aggregation strategies and all the groups\n",
      "2022-09-14 17:07:43.310520 fold_2: Generate GRS for all the aggregation strategies and all the groups\n",
      "2022-09-14 17:07:59.028854 fold_3: Generate GRS for all the aggregation strategies and all the groups\n",
      "2022-09-14 17:08:14.497576 fold_4: Generate GRS for all the aggregation strategies and all the groups\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "lst = os.listdir(preprocessed_dataset_folder)\n",
    "folds = [i for i in lst if os.path.isdir(preprocessed_dataset_folder+\"/\"+i)]\n",
    "\n",
    "for f in folds:\n",
    "    current_fold = int(f.replace(\"fold_\",\"\"))\n",
    "    path_to_fold = preprocessed_dataset_folder+\"/\"+f\n",
    "    \n",
    "    train_df = pickle.load(open(path_to_fold+\"/train_df.pkl\", \"rb\"))\n",
    "    test_df = pickle.load(open(path_to_fold+\"/test_df.pkl\", \"rb\"))\n",
    "    test_pred_df = pickle.load(open(path_to_fold+\"/test_pred_df.pkl\", \"rb\"))\n",
    "    \n",
    "    \n",
    "\n",
    "    print(datetime.now(), f+\": Generate GRS for all the aggregation strategies and all the groups\")\n",
    "    # - generate the recommendations for all the aggregation strategies and all the groups\n",
    "    group_recommendations = generate_group_recommendations_forall_groups(test_pred_df, group_composition, cfg.recommendations_number)\n",
    "    \n",
    "    pickle.dump(group_recommendations, open(path_to_fold+\"/group_recommendations.pkl\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-14 17:05:56.635039 fold_0: Evaluate Group recommendations\n",
      "2022-09-14 17:06:06.034420 Fold Evaluation DONE\n",
      "2022-09-14 17:06:06.158062 fold_1: Evaluate Group recommendations\n",
      "2022-09-14 17:06:15.390396 Fold Evaluation DONE\n",
      "2022-09-14 17:06:15.509454 fold_2: Evaluate Group recommendations\n",
      "2022-09-14 17:06:24.697338 Fold Evaluation DONE\n",
      "2022-09-14 17:06:24.814608 fold_3: Evaluate Group recommendations\n",
      "2022-09-14 17:06:34.168531 Fold Evaluation DONE\n",
      "2022-09-14 17:06:34.290088 fold_4: Evaluate Group recommendations\n",
      "2022-09-14 17:06:43.661766 Fold Evaluation DONE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "lst = os.listdir(preprocessed_dataset_folder)\n",
    "folds = [i for i in lst if os.path.isdir(preprocessed_dataset_folder+\"/\"+i)]\n",
    "\n",
    "evaluations = list()\n",
    "for f in folds:\n",
    "    current_fold = int(f.replace(\"fold_\",\"\"))\n",
    "    path_to_fold = preprocessed_dataset_folder+\"/\"+f\n",
    "    \n",
    "    train_df = pickle.load(open(path_to_fold+\"/train_df.pkl\", \"rb\"))\n",
    "    test_df = pickle.load(open(path_to_fold+\"/test_df.pkl\", \"rb\"))\n",
    "    test_pred_df = pickle.load(open(path_to_fold+\"/test_pred_df.pkl\", \"rb\"))\n",
    "    group_recommendations = pickle.load(open(path_to_fold+\"/group_recommendations.pkl\", \"rb\"))\n",
    "    \n",
    "    # - evaluate the recommendations\n",
    "    if cfg.evaluation_strategy == \"COUPLED\":\n",
    "        ground_truth = test_df\n",
    "    else:\n",
    "        ground_truth = test_pred_df.rename(columns={\"predicted_rating\": \"rating\"}, errors=\"raise\")\n",
    "    \n",
    "    if cfg.inverse_propensity_debiasing == True and cfg.evaluation_strategy == \"COUPLED\":\n",
    "        propensity_per_item = calculate_inverse_propensity_score(ratings_df, train_df, cfg.inverse_propensity_gamma)\n",
    "        per_user_propensity_normalization_term = calculate_inverse_propensity_score_user_normalization(propensity_per_item, test_df)\n",
    "    else:\n",
    "        #dummies to simplify downstream code\n",
    "        propensity_per_item = pd.Series({\"propensity_score\":1.0})\n",
    "        per_user_propensity_normalization_term = None\n",
    "        \n",
    "    print(datetime.now(), f+\": Evaluate Group recommendations\")\n",
    "    fold_group_evaluations = evaluate_group_recommendations_forall_groups(ground_truth, group_recommendations, group_composition, current_fold)\n",
    "    print(datetime.now(), \"Fold Evaluation DONE\")\n",
    "    #display(fold_group_evaluations)\n",
    "    \n",
    "    evaluations = evaluations + fold_group_evaluations\n",
    "    #current_fold = current_fold + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(evaluations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>aggr_metric</th>\n",
       "      <th>value</th>\n",
       "      <th>aggregation_strategy</th>\n",
       "      <th>group_id</th>\n",
       "      <th>current_fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.019192</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>minmax</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DCG</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.945834</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DCG</td>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28795</th>\n",
       "      <td>BoundedRecall</td>\n",
       "      <td>minmax</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28796</th>\n",
       "      <td>DFH</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.078306</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28797</th>\n",
       "      <td>DFH</td>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28798</th>\n",
       "      <td>DFH</td>\n",
       "      <td>minmax</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28799</th>\n",
       "      <td>zRecall</td>\n",
       "      <td>none</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28800 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              metric aggr_metric     value aggregation_strategy  group_id  \\\n",
       "0               NDCG        mean  0.019192                  ADD         0   \n",
       "1               NDCG         min  0.000000                  ADD         0   \n",
       "2               NDCG      minmax  0.000000                  ADD         0   \n",
       "3                DCG        mean  0.945834                  ADD         0   \n",
       "4                DCG         min  0.000000                  ADD         0   \n",
       "...              ...         ...       ...                  ...       ...   \n",
       "28795  BoundedRecall      minmax  0.000000             EPFuzzDA        59   \n",
       "28796            DFH        mean  0.078306             EPFuzzDA        59   \n",
       "28797            DFH         min  0.000000             EPFuzzDA        59   \n",
       "28798            DFH      minmax  0.000000             EPFuzzDA        59   \n",
       "28799        zRecall        none  0.750000             EPFuzzDA        59   \n",
       "\n",
       "       current_fold  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "28795             4  \n",
       "28796             4  \n",
       "28797             4  \n",
       "28798             4  \n",
       "28799             4  \n",
       "\n",
       "[28800 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame.from_records(evaluations)\n",
    "display(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_folds = eval_df.groupby(['metric', 'aggr_metric', 'aggregation_strategy', 'group_id']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>aggr_metric</th>\n",
       "      <th>aggregation_strategy</th>\n",
       "      <th>group_id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BoundedRecall</td>\n",
       "      <td>mean</td>\n",
       "      <td>ADD</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>BoundedRecall</td>\n",
       "      <td>min</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4140</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LMS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>minmax</td>\n",
       "      <td>GFAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0.143581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>minmax</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>min</td>\n",
       "      <td>MUL</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>minmax</td>\n",
       "      <td>ADD</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>minmax</td>\n",
       "      <td>EPFuzzDA</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>NDCG</td>\n",
       "      <td>mean</td>\n",
       "      <td>MPL</td>\n",
       "      <td>59</td>\n",
       "      <td>0.051309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>zRecall</td>\n",
       "      <td>none</td>\n",
       "      <td>MUL</td>\n",
       "      <td>59</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5760 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             metric aggr_metric aggregation_strategy  group_id     value\n",
       "0     BoundedRecall        mean                  ADD         0  0.050000\n",
       "420   BoundedRecall         min             EPFuzzDA         0  0.010000\n",
       "4140           NDCG      minmax                  LMS         0  0.084711\n",
       "4080           NDCG      minmax                 GFAR         0  0.143581\n",
       "4020           NDCG      minmax             EPFuzzDA         0  0.090338\n",
       "...             ...         ...                  ...       ...       ...\n",
       "3959           NDCG         min                  MUL        59  0.000000\n",
       "4019           NDCG      minmax                  ADD        59  0.000000\n",
       "4079           NDCG      minmax             EPFuzzDA        59  0.000000\n",
       "3539           NDCG        mean                  MPL        59  0.051309\n",
       "5759        zRecall        none                  MUL        59  0.875000\n",
       "\n",
       "[5760 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(group_folds['value'].reset_index().sort_values(by='group_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>group_id</th>\n",
       "      <th>current_fold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>aggr_metric</th>\n",
       "      <th>aggregation_strategy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">BoundedRecall</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">mean</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.043101</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.045542</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>0.046051</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>0.042213</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>0.049808</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>0.041836</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">min</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.006982</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.008646</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>0.005493</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>0.007659</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>0.005978</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>0.006888</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">minmax</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.038519</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.041869</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>0.032282</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>0.035364</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>0.038897</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>0.039357</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">DCG</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">mean</th>\n",
       "      <th>ADD</th>\n",
       "      <td>1.721625</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>1.727746</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>1.603163</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>1.598030</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>1.832524</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>1.713527</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">min</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.296986</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.292900</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>0.174827</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>0.268586</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>0.290005</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>0.308490</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">minmax</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.048318</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.043264</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>0.038154</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>0.040477</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>0.052305</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>0.046739</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">DFH</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">mean</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.153801</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.151365</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>0.154614</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>0.139362</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>0.161513</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>0.152498</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">min</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.028913</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.026015</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFAR</th>\n",
       "      <td>0.019690</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMS</th>\n",
       "      <td>0.022990</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPL</th>\n",
       "      <td>0.027370</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>0.028152</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">minmax</th>\n",
       "      <th>ADD</th>\n",
       "      <td>0.050484</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPFuzzDA</th>\n",
       "      <td>0.049615</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   value  group_id  \\\n",
       "metric        aggr_metric aggregation_strategy                       \n",
       "BoundedRecall mean        ADD                   0.043101      29.5   \n",
       "                          EPFuzzDA              0.045542      29.5   \n",
       "                          GFAR                  0.046051      29.5   \n",
       "                          LMS                   0.042213      29.5   \n",
       "                          MPL                   0.049808      29.5   \n",
       "                          MUL                   0.041836      29.5   \n",
       "              min         ADD                   0.006982      29.5   \n",
       "                          EPFuzzDA              0.008646      29.5   \n",
       "                          GFAR                  0.005493      29.5   \n",
       "                          LMS                   0.007659      29.5   \n",
       "                          MPL                   0.005978      29.5   \n",
       "                          MUL                   0.006888      29.5   \n",
       "              minmax      ADD                   0.038519      29.5   \n",
       "                          EPFuzzDA              0.041869      29.5   \n",
       "                          GFAR                  0.032282      29.5   \n",
       "                          LMS                   0.035364      29.5   \n",
       "                          MPL                   0.038897      29.5   \n",
       "                          MUL                   0.039357      29.5   \n",
       "DCG           mean        ADD                   1.721625      29.5   \n",
       "                          EPFuzzDA              1.727746      29.5   \n",
       "                          GFAR                  1.603163      29.5   \n",
       "                          LMS                   1.598030      29.5   \n",
       "                          MPL                   1.832524      29.5   \n",
       "                          MUL                   1.713527      29.5   \n",
       "              min         ADD                   0.296986      29.5   \n",
       "                          EPFuzzDA              0.292900      29.5   \n",
       "                          GFAR                  0.174827      29.5   \n",
       "                          LMS                   0.268586      29.5   \n",
       "                          MPL                   0.290005      29.5   \n",
       "                          MUL                   0.308490      29.5   \n",
       "              minmax      ADD                   0.048318      29.5   \n",
       "                          EPFuzzDA              0.043264      29.5   \n",
       "                          GFAR                  0.038154      29.5   \n",
       "                          LMS                   0.040477      29.5   \n",
       "                          MPL                   0.052305      29.5   \n",
       "                          MUL                   0.046739      29.5   \n",
       "DFH           mean        ADD                   0.153801      29.5   \n",
       "                          EPFuzzDA              0.151365      29.5   \n",
       "                          GFAR                  0.154614      29.5   \n",
       "                          LMS                   0.139362      29.5   \n",
       "                          MPL                   0.161513      29.5   \n",
       "                          MUL                   0.152498      29.5   \n",
       "              min         ADD                   0.028913      29.5   \n",
       "                          EPFuzzDA              0.026015      29.5   \n",
       "                          GFAR                  0.019690      29.5   \n",
       "                          LMS                   0.022990      29.5   \n",
       "                          MPL                   0.027370      29.5   \n",
       "                          MUL                   0.028152      29.5   \n",
       "              minmax      ADD                   0.050484      29.5   \n",
       "                          EPFuzzDA              0.049615      29.5   \n",
       "\n",
       "                                                current_fold  \n",
       "metric        aggr_metric aggregation_strategy                \n",
       "BoundedRecall mean        ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "              min         ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "              minmax      ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "DCG           mean        ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "              min         ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "              minmax      ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "DFH           mean        ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "              min         ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  \n",
       "                          GFAR                           2.0  \n",
       "                          LMS                            2.0  \n",
       "                          MPL                            2.0  \n",
       "                          MUL                            2.0  \n",
       "              minmax      ADD                            2.0  \n",
       "                          EPFuzzDA                       2.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.groupby(['metric', 'aggr_metric', 'aggregation_strategy']).mean().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
